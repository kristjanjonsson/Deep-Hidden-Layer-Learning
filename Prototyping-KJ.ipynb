{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristjanjonsson/Development/Notebooks/venv/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from utils import effectiveDimension, factorize, gram, hiddenTargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_img(filename):\n",
    "    '''Parses mnist images in filename.'''\n",
    "    f = gzip.open(filename)\n",
    "    arr = np.frombuffer(f.read(), dtype=np.dtype('>u1'), offset=16)\n",
    "    f.close()\n",
    "    return arr.reshape((-1, 28*28))\n",
    "\n",
    "def parse_label(filename):\n",
    "    '''Parses mnist labels in filename.'''\n",
    "    f = gzip.open(filename)\n",
    "    arr = np.frombuffer(f.read(), dtype=np.dtype('>u1'), offset=8)\n",
    "    f.close()\n",
    "    return arr\n",
    "\n",
    "def parseNoisyExamples(filename):\n",
    "    with open(filename) as f:\n",
    "        arr = np.loadtxt(filename, dtype=np.float32)\n",
    "        imgs = arr[:,:28*28]\n",
    "        labels = arr[:,28*28]\n",
    "        labels = labels.astype(np.int)\n",
    "    return (imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) float32\n",
      "(50000,) int64\n"
     ]
    }
   ],
   "source": [
    "(X_data, y_data) = parseNoisyExamples('mnist data/mnist_background_images_test.amat')\n",
    "print(X_data.shape, X_data.dtype)\n",
    "print(y_data.shape, y_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) uint8\n",
      "(60000,) uint8\n"
     ]
    }
   ],
   "source": [
    "X_data = parse_img('mnist data/train-images-idx3-ubyte.gz')\n",
    "y_data = parse_label('mnist data/train-labels-idx1-ubyte.gz')\n",
    "print(X_data.shape, X_data.dtype)\n",
    "print(y_data.shape, y_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC1CAYAAAAZU76pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14a118080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_img(x):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(x.reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "idx = np.random.randint(0, len(X_data))\n",
    "plot_img(X_data[idx])\n",
    "print('Label = ' + str(y_data[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6131, 784)\n",
      "(5851, 784)\n",
      "\n",
      "(11982, 784)\n",
      "(11982,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 3s and 8s.\n",
    "X3 = X_data[y_data == 3]\n",
    "X8 = X_data[y_data == 8]\n",
    "print(X3.shape)\n",
    "print(X8.shape)\n",
    "print()\n",
    "\n",
    "X = np.vstack([X3, X8])\n",
    "y = np.concatenate([[-1] * len(X3), [1] * len(X8)])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessX(X):\n",
    "    m = np.mean(X, axis=0)\n",
    "    X = X - m\n",
    "    norms = np.linalg.norm(X, axis=1)\n",
    "    mNorm = np.mean(norms)\n",
    "    X = X / mNorm\n",
    "    return X\n",
    "\n",
    "X = preprocessX(X.astype(float))\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6131, 784)\n",
      "(5851, 784)\n",
      "\n",
      "(11982, 784)\n",
      "(11982,)\n",
      "\n",
      "(11970, 784)\n",
      "(11970,)\n",
      "(12, 784)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.999)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of sample image is -1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC1CAYAAAAZU76pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107be6438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check.\n",
    "sampleImgIdx = np.random.randint(0, len(X_train))\n",
    "sampleImg = X_train[sampleImgIdx]\n",
    "sampleLabel = y_train[sampleImgIdx]\n",
    "print('Label of sample image is ' + str(sampleLabel))\n",
    "plot_img(sampleImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "1. Plot eigenvalues as a function of i where i is the ith largest eigenvalue. Do for different $\\alpha \\in [0, 1]$\n",
    "1. Plot $d_{95}$ (effective dimension) as a function of $\\alpha$.\n",
    "1. Logistic (or SVM) error as a function of $\\alpha$. (note hidden targest are input an label targets). \n",
    "\n",
    "Question:\n",
    "Throw away eigenvalues below some threshold. Not the same as $d_{95}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO function\n",
    "To help with saving and loading experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from glob import fnmatch\n",
    "\n",
    "def filePrefix(alpha):\n",
    "    '''x is a float.'''\n",
    "    s = '{0:.12f}'.format(alpha)\n",
    "    prefix = s.replace('.', '_')\n",
    "    return 'alpha_' + prefix + '_'\n",
    "\n",
    "\n",
    "def createSaveDirectory():\n",
    "    '''Creates a unique directory in data/ based on timestamp.'''\n",
    "    directoryName = str(int(time()))\n",
    "    path = join('data', directoryName)\n",
    "    !mkdir $path\n",
    "    assert isdir(path), 'Directory does not exist\\n{0}'.format(path)\n",
    "    return path\n",
    "\n",
    "    \n",
    "def save(arr, alpha, path, which): \n",
    "    '''\n",
    "    arr: The numpy array to save.\n",
    "    alpha: The alpha associated with this calculation. See above definition.\n",
    "    path: the directory to store the data.\n",
    "    which: either \"eigvals\" or \"H\".\n",
    "    \n",
    "    returns an iterator of stored eigvals or H.\n",
    "    '''\n",
    "    fname = join(path, filePrefix(alpha) + which)\n",
    "    np.save(fname, arr)\n",
    "    print('Saved: ' + fname)\n",
    "  \n",
    "\n",
    "def load(path, which):\n",
    "    '''\n",
    "    path: the directory of the data.\n",
    "    which: either \"eigvals\" or \"H\".\n",
    "    \n",
    "    returns an iterator of stored eigvals or H.\n",
    "    '''\n",
    "    fnames = fnmatch.filter(os.listdir(path), '*{0}*'.format(which))\n",
    "    print('Loading: {0}, from {1}'.format(','.join(sorted(fnames)), path))\n",
    "    for fname in sorted(fnames):\n",
    "        fullPath = join(path, fname)\n",
    "        \n",
    "        yield np.load(fullPath)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in dir: data/1457076696\n",
      "Saved: data/1457076696/alpha_0_000000000010_H\n",
      "Saved: data/1457076696/alpha_0_000000000010_eigvals\n",
      "Saved: data/1457076696/alpha_0_000000000030_H\n",
      "Saved: data/1457076696/alpha_0_000000000030_eigvals\n",
      "Saved: data/1457076696/alpha_0_000000000100_H\n",
      "Saved: data/1457076696/alpha_0_000000000100_eigvals\n",
      "Saved: data/1457076696/alpha_0_000000000300_H\n",
      "Saved: data/1457076696/alpha_0_000000000300_eigvals\n",
      "Saved: data/1457076696/alpha_0_000000001000_H\n",
      "Saved: data/1457076696/alpha_0_000000001000_eigvals\n",
      "Saved: data/1457076696/alpha_0_000000003000_H\n",
      "Saved: data/1457076696/alpha_0_000000003000_eigvals\n"
     ]
    }
   ],
   "source": [
    "def computeHiddenTargets(alphas, X, y):\n",
    "    XG = gram(X)\n",
    "    YG = np.outer(y, y)\n",
    "\n",
    "    path = createSaveDirectory()\n",
    "    print('Saving results in dir: ' + path)\n",
    "    np.save(join(path, 'alphas'), alphas)\n",
    "    np.save(join(path, 'X'), X)\n",
    "    np.save(join(path, 'y'), y)\n",
    "    for alpha in alphas:\n",
    "        H, eigvals = hiddenTargets(XG, YG, alpha)\n",
    "        save(H, alpha, path, 'H')\n",
    "        save(eigvals, alpha, path, 'eigvals')\n",
    "\n",
    "alphas = np.array([1e-11, 3e-11, 1e-10, 3e-10, 1e-9, 3e-9])\n",
    "computeHiddenTargets(alphas, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_number = 'mnist_1456811360'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: alpha_0_000000000010_eigvals.npy,alpha_0_000000000030_eigvals.npy,alpha_0_000000000100_eigvals.npy,alpha_0_000000000300_eigvals.npy,alpha_0_000000001000_eigvals.npy,alpha_0_000000003000_eigvals.npy,alpha_0_00000001_eigvals.npy,alpha_0_00000003_eigvals.npy,alpha_0_0000001_eigvals.npy,alpha_0_0000003_eigvals.npy,alpha_0_000001_eigvals.npy,alpha_0_000003_eigvals.npy,alpha_0_000010_eigvals.npy,alpha_0_000030_eigvals.npy,alpha_0_000100_eigvals.npy,alpha_0_000300_eigvals.npy,alpha_0_001000_eigvals.npy,alpha_0_003000_eigvals.npy,alpha_0_010000_eigvals.npy,alpha_0_030000_eigvals.npy, from data/mnist_1456811360/\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFVCAYAAADsaJZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQh4AgCBFyAMAEKT+H2j+4E3tLQ/0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x148d35c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigvals = load('data/{0}/'.format(experiment_number), which='eigvals')\n",
    "# alphas = np.arange(0, 1.05, 0.05)\n",
    "p95 = np.array([effectiveDimension(eigval, p=0.95) for eigval in eigvals])\n",
    "plt.plot(alphas, p95);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: alpha_0_0000000001_eigvals.npy,alpha_0_0000000003_eigvals.npy,alpha_0_0000000010_eigvals.npy,alpha_0_0000000030_eigvals.npy,alpha_0_0000000100_eigvals.npy,alpha_0_0000000300_eigvals.npy,alpha_0_0000001000_eigvals.npy,alpha_0_0000003000_eigvals.npy,alpha_0_0000010000_eigvals.npy,alpha_0_0000030000_eigvals.npy, from data/1456993244/\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFVCAYAAADG2GfeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X90VPWd//Hn596ZSTKZhCBGCoJEMbQgKbKga9c1tSvu\nyrqtgrUVBHXFHtlvPaXFWqzStVpa2O6y7p6tnOP3S0+3gqvQLVbdrdstrcZuZVdKLQiIv9DKAkKC\nQDIzyfy4937/mCSiItwAyb0383qck5PJzSR5z9uR151773zexvM8DxEREYkMK+gCREREpG8U3iIi\nIhGj8BYREYkYhbeIiEjEKLxFREQiRuEtIiISMbFjfbNYLHLXXXexe/duCoUC8+fPZ8SIEdx66600\nNDQAMGvWLKZPn87atWtZs2YN8Xic+fPnc+mll5LL5bjjjjs4cOAAqVSKZcuWMXTo0IF4XCIiIoOW\nOdb7vNetW8fLL7/M17/+dQ4fPszVV1/NF7/4RdLpNDfddFPv/dra2vjLv/xLHnvsMbq6upg1axbr\n1q3j4YcfJp1Oc9ttt/HTn/6UF154gbvvvnsgHpeIiMigdczD5tOnT2fBggUAuK5LLBZj27ZtPP30\n08yZM4fFixeTyWTYsmULU6ZMIRaLkUqlaGhoYMeOHWzatInm5mYAmpub2bBhQ/8/IhERkUHumIfN\nq6qqAEin0yxYsIAvf/nL5PN5rr32WiZMmMCDDz7I9773PcaPH09NTU3vzyWTSdLpNJlMhlQqBUB1\ndTXpdLofH4qIiEh5OO4Fa3v37uXGG29kxowZXHnllUybNo0JEyYAMG3aNHbs2EFNTc17gjmTyVBb\nW0sqlSKTyfRuOzLgj+Vvv/zAiTwWERGRsnDMV95tbW3MmzePv/7rv+aiiy4C4JZbbmHx4sU0NTWx\nYcMGzjvvPJqamrj//vvJ5/Pkcjl27txJY2MjkydPpqWlhaamJlpaWpg6daqvoowXo7W14+Qf3SBX\nX1+jPvmgPvmnXvmjPvmnXvlTX+/vxW2PY4b3gw8+SHt7OytWrOCBBx7AGMNdd93Fd77zHeLxOPX1\n9dx3331UV1czd+5cZs+ejed5LFy4kEQiwaxZs1i0aBGzZ88mkUiwfPlyX0V5XrxPD0JERKScHPNq\n86D8zYLV3Lz4qqDLCD3t0fqjPvmnXvmjPvmnXvnT11feoVykxTGJoEsQEREJrXCGt1VBNpsNugwR\nEZFQCmV4e8Zi69ZtQZchIiISSqEMb4D/fWtX0CWIiIiEUmjDO31YC7qIiIgcTWjDu9BZCLoEERGR\nUApteHsFN+gSREREQim04W2KJugSREREQim84e0ovEVERI4mtOFtOXbQJYiIiIRSaMPbeApvERGR\nowlteGs4iYiIyNGFMrwtt4Cn9c1FRESOKpThHXPzuCi8RUREjiaU4W15ORyrIugyREREQimU4W0o\n4Fhxdu/ZE3QpIiIioRPO8DalpVG3bd0ecCUiIiLhE8rw9kwRgLb9bQFXIiIiEj7hDG+7tK55V0c2\n4EpERETCJ5Th7Vql8HbzGk4iIiLyfqEMby/mAWCKXsCViIiIhE8ow9skSmVpOImIiMgHhTK841Wl\npVGNE8ryREREAhXKdKwdWgOAcTWcRERE5P1CGd5jzj2rdEPDSURERD4glOH9h1Mng+cqvEVERI4i\nlOE9ZMiQ0nASTRYTERH5gFCGN4DtKbxFRESOJrThbXl5ilYF2axWWRMRETlSaMPbmAKesdj20stB\nlyIiIhIqoQ1vr3uy2K7f/z7gSkRERMIlxOHtAJA+1BFwJSIiIuES3vDunixWyBYCrkRERCRcQhve\nbnd4ewUn4EpERETCJbThTaz0yRSDLUNERCRsQhveVkVpXXMNJxEREXmv0CZjoroC0HASERGR9wtt\neA8ddhoAlsJbRETkPUIb3uPGjQPA03ASERGR9whteDc2jsVyi3govEVERI4U2vAGsL0crqkIugwR\nEZFQCXl453EsTRYTERE5UqjD23SH9+49e4IuRUREJDRCHd50DyfZocliIiIivUIe3qWlUfe/vT/g\nQkRERMIj1OHt2aW1Ubs6OgOuREREJDxCHd6u5QHg5LTAuYiISI9Qh7cXK4W3KXoBVyIiIhIeoQ5v\n4qb0uWiCrUNERCREQh3escrS6mpa31xERORdoQ7vZG0KAOOGukwREZEBFepUPPPMEQAYDScRERHp\nFerwnjDxPPA8PC8WdCkiIiKhEerwHlo3hJibxzNa31xERKTHMV/SFotF7rrrLnbv3k2hUGD+/Pmc\ne+653HnnnViWRWNjI/fccw8Aa9euZc2aNcTjcebPn8+ll15KLpfjjjvu4MCBA6RSKZYtW8bQoUP7\nVKDt5XA0WUxERKTXMV95P/HEEwwdOpSHH36YlStX8q1vfYulS5eycOFCVq9ejeu6rF+/nra2Nlat\nWsWaNWtYuXIly5cvp1Ao8MgjjzBu3DgefvhhrrrqKlasWNH3Ar08RStBNps94QcpIiIymBwzvKdP\nn86CBQsAcBwH27bZvn07U6dOBaC5uZnnnnuOLVu2MGXKFGKxGKlUioaGBnbs2MGmTZtobm7uve+G\nDRv6XqEp4BmbV159re8/KyIiMggd87B5VVUVAOl0mgULFvCVr3yFv/mbv+n9fnV1Nel0mkwmQ01N\nTe/2ZDLZuz2VSr3nvn7V13f/PlNaGnXPnl1cPu1i3z9fLnr7JMekPvmnXvmjPvmnXp16x72Me+/e\nvdx2223MmTOHK6+8kr/927/t/V4mk6G2tpZUKvWeYD5yeyaT6d12ZMAfT2trR+lGd3i37X3n3W0C\nlP6HUE+OT33yT73yR33yT73yp687OMc8bN7W1sa8efO44447mDFjBgDjx49n48aNADz77LNMmTKF\npqYmNm3aRD6fp6Ojg507d9LY2MjkyZNpaWkBoKWlpfdwe1+4tgtAvjPf558VEREZjI75yvvBBx+k\nvb2dFStW8MADD2CM4e6772bJkiUUCgXGjh3LFVdcgTGGuXPnMnv2bDzPY+HChSQSCWbNmsWiRYuY\nPXs2iUSC5cuX97lAz3ahCOQ1nERERATAeJ4XylTsOcyy8h/+H4WuRhL2a8y745aAqwoXHY7yR33y\nT73yR33yT73y55QeNg8DkygNJbEcTRYTERGBCIR3IllaoMVospiIiAgQgfAeMqyudEPhLSIiAkQg\nvBvHjgXAoMliIiIiEIHwHtNwFsZ18BTeIiIiQATCO5lMEvNyOGiymIiICEQgvKF7spilyWIiIiIQ\nkfA2XgHHStB64EDQpYiIiAQuGuFtCgBs3fxiwJWIiIgELxLh7XUPJ9m3b3/AlYiIiAQvGuFtOwB0\ntmcDrkRERCR40QhvqzRZzMkVA65EREQkeJEIbzdWmp1iCqGcoSIiIjKgIhHeJl4aSmI0nERERCQa\n4W11TxYzTiTKFRER6VeRSMNkbTWgyWIiIiIQkfAePnIEAMaLBVyJiIhI8CIR3udNnACA52k4iYiI\nSCTCu37YMGwnh2c0nERERCQS4Q0Q8/I4Cm8REZHohLfl5ShaFWSzWmVNRETKW2TC21DAMzavv7kz\n6FJEREQCFZnw9qzS0qg7X3sj4EpERESCFZnwpnuyWPuBQwEXIiIiEqzIhLdrl4aT5LO5gCsREREJ\nVmTC2+sOby+v4SQiIlLeIhTepc9GU0FFRKTMRSa8TaJ7spgbmZJFRET6RWSSMJGsAMDSZDERESlz\nkUnC2mF1pRsaTiIiImUuMuF9zrlnA2BchbeIiJS3yIT32IZzMJ6DhyaLiYhIeYtMeCeTSWJuDtdU\nBF2KiIhIoCIT3gC2l6eoyWIiIlLmIhXexsvj2BW0HjgQdCkiIiKBiVZ4mwIA27ZuD7gSERGR4EQq\nvL3u5dX27dkbcCUiIiLBiVZ4Ww4A2fZMwJWIiIgEJ1rh3T2cxMk7AVciIiISnIiFd/dEMU0WExGR\nMhat8I6XhpNYjgm4EhERkeBEKrztitLSqJosJiIi5SxSKVhVmwTAOHbAlYiIiAQnUuE9fPgZABhN\nFhMRkTIWqfCeOKkJAM/TcBIRESlfkQrv+mHDsN08nlF4i4hI+YpUeAPYbg5Hk8VERKSMRS+8yVM0\nFWSz2aBLERERCUTkwhvyeJbN7998K+hCREREAhG58DaUhpO8+vrrAVciIiISjMiFt2eVwvvwgYMB\nVyIiIhKMCIZ3aThJPpMLuBIREZFgRC683e7hJF7BDbgSERGRYPgK782bNzN37lwAXnrpJZqbm7nh\nhhu44YYbeOqppwBYu3Yt11xzDddddx3PPPMMALlcji996Utcf/313HrrrRw8ePKHunsWVzPFk/5V\nIiIikXTcdUZXrlzJ448/TnV1NQBbt27l5ptv5qabbuq9T1tbG6tWreKxxx6jq6uLWbNmcfHFF/PI\nI48wbtw4brvtNn7605+yYsUK7r777pOrOGEgB8aJ3EEDERGRU+K4CThmzBgeeOCB3q+3bdvGM888\nw5w5c1i8eDGZTIYtW7YwZcoUYrEYqVSKhoYGduzYwaZNm2hubgagubmZDRs2nHTBiapEqXCFt4iI\nlKnjJuDll1+Obb87xWvSpEl87WtfY/Xq1YwePZrvfe97pNNpampqeu+TTCZJp9NkMhlSqRQA1dXV\npNPpky54yGlDSjc0nERERMpUnxNw2rRpvUE9bdo0lixZwoUXXvieYM5kMtTW1pJKpchkMr3bjgz4\n46mvP/p9z2saz54du8GLfeh9yol64I/65J965Y/65J96der1ObxvueUWFi9eTFNTExs2bOC8886j\nqamJ+++/n3w+Ty6XY+fOnTQ2NjJ58mRaWlpoamqipaWFqVOn+v47ra0dR90+csSZGO8t8OIfep9y\nUV9fU/Y98EN98k+98kd98k+98qevOzh9Du97772Xe++9l3g8Tn19Pffddx/V1dXMnTuX2bNn43ke\nCxcuJJFIMGvWLBYtWsTs2bNJJBIsX768r3/uA5LJJDE3h2sSJ/27REREosh4nucFXcTRHGtP7QdL\nfkLRVPGFu/9sACsKH+3R+qM++ade+aM++ade+dPXV96RvGTbeHmKVoKDhw4HXYqIiMiAi2R4Ywpg\nDC9u2RJ0JSIiIgMuouFdWl5t7563Ay5ERERk4EUyvHuGk3R2ZAOuREREZOBFMrxdywGg2FUIuBIR\nEZGBF8nwJtZ9gXwhlBfKi4iI9KtIhrcXMwCYogm4EhERkYEXyfC2K0pry1iuwltERMpPJMO7sqYK\nAONoOImIiJSfSIb3GR85o3TDs499RxERkUEokuE9sWlC6YYXD7YQERGRAEQyvIefMRzbzeNpOImI\niJShSIY3gO3mcBTeIiJShiIb3paXxzEVQZchIiIy4CIb3oYCrhXj1VdfD7oUERGRARXd8DalpVFf\neeWVgCsREREZWJEN7571zQ8eeCfgSkRERAZWZMPb6w7vfCYXcCUiIiIDK7rhbZfGgro5J+BKRERE\nBlZ0w7tnZdRioGWIiIgMuMiGt4mXlka1nMg+BBERkRMS2eSLJ0tLoxqFt4iIlJnIJl9NXS0ARsNJ\nRESkzEQ2vBvOaQDAaDiJiIiUmciG90fHNWI8F0/hLSIiZSay4Z1MJom5OVwNJxERkTIT2fCGnuEk\nCm8RESkvkQ/vopWgPd0edCkiIiIDJtLhjSmAsdj64vagKxERERkw0Q9vYM+u3QEXIiIiMnAiHd49\nw0kyh9MBVyIiIjJwoh3e3cNJil2FgCsREREZOBEPb6/0ueAFXImIiMjAiXZ4xwwApmgCrkRERGTg\nRDq8rYruyWJupB+GiIhIn0Q69SpTlYAmi4mISHmJdOrVDz8DAOPFAq5ERERk4EQ6vCecNx5Aw0lE\nRKSsRDq8zxw5Etst4KHwFhGR8hHp8Aaw3RyuqQi6DBERkQET+fC2KA0nERERKReRD2/j5XGtOG++\n8UbQpYiIiAyI6Id393CSl3a8EnAlIiIiAyPy4e2Z0nCSA63vBFyJiIjIwIh8eLt2Kbzzmc6AKxER\nERkYkQ/vnuEkbs4JuBIREZGBEf3wjnVPFCsGW4eIiMhAiXx4m3jpIViOJouJiEh5iHx4x6tKq6sZ\n1w64EhERkYER+fBODa0FFN4iIlI+Ih/eo0adCWiymIiIlI/Ih/fEiedhPFeTxUREpGxEPryTyWT3\ncBKtby4iIuXBV3hv3ryZuXPnAvDWW28xe/Zs5syZw7333tt7n7Vr13LNNddw3XXX8cwzzwCQy+X4\n0pe+xPXXX8+tt97KwYMHT/0jAGwvj6PJYiIiUiaOG94rV65k8eLFFAqlNcSXLl3KwoULWb16Na7r\nsn79etra2li1ahVr1qxh5cqVLF++nEKhwCOPPMK4ceN4+OGHueqqq1ixYkX/PAivNFmsPd3eL79f\nREQkTI4b3mPGjOGBBx7o/Xrbtm1MnToVgObmZp577jm2bNnClClTiMVipFIpGhoa2LFjB5s2baK5\nubn3vhs2bOiXB2FMAYzFtu07+uX3i4iIhMlxw/vyyy/Htt99G5bneb23q6urSafTZDIZampqercn\nk8ne7alU6j337Q+eKS2vtvutXf3y+0VERMKkz++vsqx38z6TyVBbW0sqlXpPMB+5PZPJ9G47MuCP\np77e/309q7SueefhTJ9+bjAot8d7otQn/9Qrf9Qn/9SrU6/P4T1hwgQ2btzIBRdcwLPPPstFF11E\nU1MT999/P/l8nlwux86dO2lsbGTy5Mm0tLTQ1NRES0tL7+F2P1pbO3zf17Mc8CDXme/Tz0VdfX1N\nWT3eE6U++ade+aM++ade+dPXHZw+h/eiRYv4xje+QaFQYOzYsVxxxRUYY5g7dy6zZ8/G8zwWLlxI\nIpFg1qxZLFq0iNmzZ5NIJFi+fHlf/5wvnu2VBpPkvePeV0REJOqMd+RJ7BDpy57ayn9cSaHzXBLW\na8z72i39WFW4aI/WH/XJP/XKH/XJP/XKn76+8o78Ii0AVqJ7spiryWIiIjL4DYrwrkhVARpOIiIi\n5WFQhPfp9cNKN1wNJxERkcFvUIT3+PPGl25oOImIiJSBQRHeZ40ejeUW8FB4i4jI4Dcowhsgpsli\nIiJSJgZNeJeGk2iymIiIDH6DJrwNBVwrzlu7tL65iIgMboMmvDGlkaUvbXsp4EJERET61+AJb6s0\nWayt9UDAhYiIiPSvQRPeruUCkEt3BlyJiIhI/xo04d0zFtTNuwFXIiIi0r8GT3h3v8XbFEI5Z0VE\nROSUGTThbVWVlka1c3qvt4iIDG6DJrxnXDeTRDFNzoxk46YXgi5HRESk3wya8B5aNwQTfxvXirPl\nl78JuhwREZF+M2jCG2DM1LEYz8HK1ZPNZoMuR0REpF8MqvC+7LJPUenspStWx5pVa4MuR0REpF8M\nqvAGcIflATCtdsCViIiI9I9BF97X3XgdFcXDdNkjeablV0GXIyIicsoNuvBOJpN4Fa14xub1/345\n6HJEREROuUEX3gBNn5yE5RahMJz2dHvQ5YiIiJxSgzK8L7zwAiq83eRjNfzon/816HJEREROqUEZ\n3gDWiNJDsw9VBlyJiIjIqTVow/uGm+dSWThAp/0R/v3fnwq6HBERkVNm0IY3gJt8B4zFvhf3BF2K\niIjIKTOow/uPpl+C7eZxnRHs278v6HJEREROiUEd3uMnfIwEeyjYSZ585MmgyxERETklBnV4A1SM\nqQIg1l4TcCUiIiKnxqAP71nXf56qwn4648P517U/DrocERGRkzbowxugmDoMQMfrhwOuRERE5OSV\nRXj/6WevIOZ0UnRH8uqrrwddjoiIyEkpi/A+a/RoYtZeinYlLU/+MuhyRERETkpZhDdA3UeHgecR\nywwNuhQREZGTUjbhPWPmVSSLb9MZP53VDz0cdDkiIiInrGzCG6BYlyl93lUIuBIREZETV1bhPXPu\ntSSKGfLmTH63eUvQ5YiIiJyQsgrvoXVDMPG3caw4v/n5/wRdjoiIyAkpq/AGGDV5DMZzsbtOJ5vN\nBl2OiIhIn5VdeP/pn06j0tlDV2woax/+UdDliIiI9FnZhTeAOyxfurG/LB++iIhEXFmm13U3XkdF\nsZ0uM5Jf/9dzQZcjIiLSJ2UZ3slkEi+xH8+yefm57UGXIyIi0idlGd4A4y+ZiOUWIX8G7en2oMsR\nERHxrWzD+48+cREV3h5ysVp+9ENduCYiItFRtuENYM7wAIgdrAy4EhEREf/KOryvvf5aKgvv0GmP\n4Gf/8Z9BlyMiIuJLWYd3MpnErTqAZyx2b94VdDkiIiK+lHV4A1z455/AdvO4xY/QeuBA0OWIiIgc\nV9mHd9OEiSTYQ8Gu5vFV64IuR0RE5LjKPrwBkmNrwHOx0/UcPHQ46HJERESOSeENfO7z11Dl/i9d\nsTp+/AO9bUxERMJN4d1tyPghGM/Fypyhc98iIhJqCu9uM2ZeRaW7i1yslsd/qHPfIiISXrET/cGZ\nM2eSSqUAGDVqFPPnz+fOO+/EsiwaGxu55557AFi7di1r1qwhHo8zf/58Lr300lNSeH+o/3g9u7Y6\nmOxH2Ld/H8PPGB50SSIiIh9wQuGdz5dGaj700EO92/7qr/6KhQsXMnXqVO655x7Wr1/P+eefz6pV\nq3jsscfo6upi1qxZXHzxxcTj8VNT/Sl25af/nH9+8Z/pjDXwbw89wbyvfiHokkRERD7ghA6b79ix\ng2w2y7x587jpppvYvHkz27dvZ+rUqQA0Nzfz3HPPsWXLFqZMmUIsFiOVStHQ0MDLL798Sh/AqTZy\n6qjSwJKukby1Swu3iIhI+JzQK+/KykrmzZvHtddey5tvvskXvvAFPM/r/X51dTXpdJpMJkNNTU3v\n9mQySUdHh6+/UV9fc/w79YPrr5/Bdzf9I12xc/j5oz/jzu9+JZA6/AqqT1GjPvmnXvmjPvmnXp16\nJxTeDQ0NjBkzpvd2XV0d27e/Oxc7k8lQW1tLKpUinU5/YLsfra3+Qr4/nP1Hjbz86y48ZyT/9etN\nfHTcuMBqOZb6+ppA+xQV6pN/6pU/6pN/6pU/fd3BOaHD5uvWrWPZsmUA7Nu3j3Q6zcUXX8zzzz8P\nwLPPPsuUKVNoampi06ZN5PN5Ojo62LlzJ42NjSfyJwfUpZ+8hIT1FgU7ya9/8mzQ5YiIiLzHCb3y\n/uxnP8tdd93F9ddfjzGGZcuWUVdXx+LFiykUCowdO5YrrrgCYwxz585l9uzZeJ7HwoULSSQSp/ox\n9IuPfvI8tj7djuOM4sXtW2maMDHokkRERAAw3pEnq0MkDIdZfrDs+3QxlgrzGjcvuiXocj5Ah6P8\nUZ/8U6/8UZ/8U6/8GZDD5uVi4uV/QMzJ4RRHs3HTC0GXIyIiAii8j+mCKZOxY7so2hVs/flvgy5H\nREQEUHgf1wWfvoiY00nBHc1zG/476HJEREQU3sfTNGEidnw3jpXg5Zbtx/8BERGRfqbw9uHiqz9J\n3MmSd0fzTMuvgi5HRETKnMLbh4+Oa8Qk9uBacd547tWgyxERkTKn8Pbp8uv+jEQxQ947i//8z/VB\nlyMiImVM4e3TWaNHQ+UeXCvGnt/8b9DliIhIGVN498Ff3PAZKooddJnRPPHkvwddjoiIlCmFdx8M\nP2M4bvJtPGPzzpa2oMsREZEypfDuo6tunElFsZ0uazTr1v0k6HJERKQMKbz7qH7YMNzq/XjGov2l\n9qDLERGRMqTwPgGf+8LnqCweotMaxdo1Pw66HBERKTMK7xNQm6rFqWkDY5F9NRt0OSIiUmYU3ifo\nc/M+R2XhHTrtUfzL6keDLkdERMqIwvsE1aZqceveAWMovOkEXY6IiJSRWNAFRNmsebNZu/ynZONn\n8oMlP8FYBynWOEz6oylcMGVy0OWJiMggpfA+CclkkopzHMwbb9NlnY5r1UEGNv3nQbb99F/x4u14\nQ+BPrvgUDWefHXS5IiIySCi8T9Ks6z8PwFu7drH+334Oh8Eq1tAVG4bH6XAYfvbI61Q4z+MmOoid\nnuDT11zF0LohAVcuIiJRZTzP84Iu4mhaWzuCLuGkvPC7zWz61UZiHTaeW0dXbGjv92wnR8Jrw6nI\nMvTsYcz87MwT+hv19TWR79NAUJ/8U6/8UZ/8U6/8qa+v6dP99cq7n0w+fxKTz5/U+/UvfvE0b2x5\njVg2geMNozN2Jjiw7zX44ZJ/wYwocsO8GwKsWEREokLhPUAuu+xTcNmner9et+4nHNzZit05lGx8\nJLTCP39rDc6wDLNuuo5kMhlgtSIiEmYK74DMnHk1ANlslkd/+ChWWzWd8eHQDmv//imKNQf53LzP\nUZuqDbhSEREJG4V3wJLJJDf/1c0APPT9h/D22mRjZ0LnMH78D7/ESbby6TmfYfgZwwOuVEREwkLh\nHSI957wffWQtXTu76LJH4eXr+Lf/uxEq9tJ89Z/Q2Dg24CpFRCRoCu8Qum7W5wB4/IkneWfrAfLW\nKFynkZa1r/Cr2NM0TdMiMCIi5UxvFYuAX/ziad7a+AYFdxSOlcB288StXZx1QQOXXXZZ0OWFnt6q\n4p965Y/65J965U9f3yqm8I6QjZte4MX1m3CKZ1K0qwCIO53E3HawszgVRWK1CSZdOJnzJ3084GrD\nQ/94+Kde+aM++ade+aPwLgOvvvo6zz7+S2Jd1RSpIR/74H/0RDFNjHbcWBdOhUPlsBSfmvZJzhw5\nMoCKg6V/PPxTr/xRn/xTr/xReJeRnv8pXty+lRc2/JbCoRx2LgZOkqJVS6H71XkP47lUOO1YpClW\ndvLxT00ti3Pn+sfDP/XKH/XJP/XKH62wVoaaJkykacLED2x/puVX7Nz+Kl7awc4nwE2St4fgWHVQ\nhN/+rI1t//FDrBEWN9w8N4DKRUTkROiVd4SdyB5tNpvlZ//xcw6+2opX+Aj5WAqAquIBnKp3+ONP\nf5KPjhvXH+UGRnv+/qlX/qhP/qlX/uiVtxxTMplkxsyrADh46DA/Xv0j4oeSZO2PQGEYLT96gw3m\n11SeXd37ljUREQkXvfKOsFO5R/vEk//OgW1v4zgjKNilddWrCvsppg4z/fNXRvpCN+35+6de+aM+\n+ade+aOIejkoAAANDElEQVRX3nJCPvPpK+HTsG//Pp78lyeIddSW1lrPncFTP9iMbf8Hp33sdK66\n+jNBlyoiUvb0yjvC+nuPds2jPyK7M03RG0nRrgDPo8p5m2JlGqvaZvS5Y7j44k+EfgKa9vz9U6/8\nUZ/8U6/80StvOWU+f921QOl95S1P/pJYZiid8RFQBA7Da5vgjY3/RcLtAJPFjeVxK1yqhqW4+I8v\nouHss4N9ACIig5TCW46rsXEsjQtLA1H+ZfWjZPd3YOdsjFOBRzVddh2eGQYe0AWF3fDUo2+ScLZi\nkwari2KiiFVtc/qo4VxyyR8ztG5IsA9KRCTCFN7SJ7PnXPeBba0HDtDy9DMc3nsQOsEuxMGtomjV\n0GmPKN2p+9X67sOwZutvSDhZLC8LVhdurICbgHgqzqhzzuITn/jD0B+KFxEJksJbTlr9sGF89rPX\nHPV7zz+/kZc2v0ShI4edt7CKCTyviqJVTS7WPaPcA3JQyMErB+C1//k1CTeDoRNMDjdexK2AeDJO\n7bA6JkwcP+jeiy4i0hcKb+lXF154ARdeeMFRv/fS9h288NsX6DyYgS6wijbGKYV7wU6VVoIDcIFO\nKHRC9gC8/coeWtw3ibldWF4OTA5METfm4NkuVBjiyQR1Zwzj/PM/Tn39hIF7wCIiA0BXm0fYYL+K\nc8Pzz/Pa9lfIHe7C5MBybIwbAzeOZypwTCUFqxKMOebvsd08tlvAUMTyCoCDMQ7g4BkXz3LBuHiW\nV/qwwcQMJmYRr0rQNPnjZTOlbbA/p04V9ck/9cofDSYpI/qfonS+/Xe//R379r5NV0cX5FysosE4\nNpYTw/MSeCaBSxzXxHBMHM+y+/x34k6GmJsGqxMnUYBqm5Fnn8knP3nJoDo/r+eUP+qTf+qVP3qr\nmJSV+mHDuPzyy459n/f947Fv/z5+/+ZbtO5rpSOdJp/topgv4hZdKHrggOUacA2WY4NbiWNqSovW\nADhAO7y5GXa98GviTjvG6n6rXKVH9ek1NH/qkkivSici4abwlrIz/IzhDD9jeJ9/7sXtW/nd/7xA\n7lAXds7CFCvwSJGLHfFWuU44tAue/OEO4s5vMTgYz8HgAi4YB4NH6ZC9B7ilz5aHZzw8PLAA4+FZ\ngAFsg7EMxjZYMRs7bhOvSJCoSFCdTJJKpTjttNP4yMgRegueSJlQeIv49GGjVw8eOszT63/Bwb3v\nYDrBKsTBTeKYKlyTwLVsXGPjmeMcru85geX0tbI88DbwNsZzSx94gPe+292fcbs/l76md3tpZ8KY\nIj3XA/ReC9B7TQBgg4lZpWsCKmJUJJMMGVLDafX1NDScRf2wYX19ACLSRwpvkZM0tG4IMz8787j3\na0+3s29vK61trXQcbieTzZLrzFHM53GKLm7RwXXcUni7HqaUseAajAd4BtP9gWcAC+MZPCyMZ+Fh\nAT2fTfeFfAaPns+l7a6J9W73MGBZpdvGfPgORulgQemj8O7mHJAGDgA7OcxveBHjOtheActzMBQx\nXrF0BKL3IkGndGShd8fAKx1hMN17L6Z7P8Z0f2BK3+u5MNHq2WzwDFhW6ciEHbOx4jaxeJxY3CZR\nUUlVZSXJqiqqa1KcdtpQ6oYOoTZV6+u/q0iYKbxFBkhtqpbaxloaG8cGXcqHsmMuv/nNi7Tub6X9\n0GE6s50Uc0XcgoNXdHuO/Jd2IlwDbmnHwXS/JPc8u/TZxHCJ4ZgKXKsa1/qQf2q6X/z3rzzwTvcH\nRxydcLG8IsZzsHCg9/SGgzEuHqUjD1DaySjtcHjvnuZ4z2kNC2NDLBHDise7T2lUUV1bQ13dEM4c\ndaaOSMgppfAWkV6nDR3C5PMnnfLfe/DQYX7/+9/Tur+Vw4cP0ZXtopgrUswXSxcJet67Id7zArzn\nqD7dr7R7g97Q++ZAr7QjUbpt9R6hKP2E1XvbYPC80pGJ0iv50hEKDxsPm6KJd5/eiB37rYc9NbhH\n/3buiNsHgNKhitKOQ2mnwek+ItF9isI78jSGC0d83fNhjMeRf9jrOSRjuq+XMN1vcew+etHzMI1t\nwHr3OgkrZmGMhTFg2TbGGIyxsGywLBvbsjB26bNlWdi2XfqIxYjbNlYiRmWigljCpjJeRUVlgoqK\nBFXJKmJWbFC96yIKFN4i0u+G1g1haF343yufzWZpO3CAt/e+zcF3DpJJp+nqylPM5SkWHLyih+eU\njkDgeqWdhd7TGlbvKY3S6Y2enQWrd8ehdFqiZ8ehtGPhmlj3bQuv9xSGhWcs/4V/yM7EqdFzviQP\nZD/8bp7bvZP17vUUBq97h8UtnTrpvoCz9xAOpSMgpesrvO7PvLtTgtf9dWl3rHe/rGf/ygDGYHr3\n00z3TgkYY4HxsCwLY5nu+1kYy8KySjswlmVj2WBbMex4DNuyiMfj2LZNPB4jXllBZaL0EYvHSVZX\nkUxWU5GIB76zovAWEemWTCY5K5nkrNGjj3m/gXjvcjabJdPZyaF3DpHJZujMdZE+3EE2k6Grs4t8\nLo9TcI5+rcR7rpOgdHqjO1J7j2Jw5BGGd9Ow59KDd7eXvud1H/Hweu7rfSBF3/3avPdaCw8b18Rx\nTaX/izcDX4HEobSz8iE7LD0Xg3pgKN1OOO1c+X8+NSCnSBTeIiIhlEwmSSaTkT9XfrQdnfZ0O3v3\nvE3b/jbaOzrIZNLkuwoUc3mcgovjOOB6pSMKnte9o9AdlEcGe88OCkd83X3FY2lbz8Wd9G7r2Qnp\n3d5zvyOulOz52SN3WEqnXo6+s9Kzo2JMFxUV8ZPumR8KbxERGVC1qVpqx9VqwNBJ6Pfw9jyPb37z\nm7z88sskEgm+/e1vM/o4h6RERETkw/XhiogTs379evL5PI8++ii33347S5cu7e8/KSIiMqj1e3hv\n2rSJSy65BIBJkyaxdevW/v6TIiIig1q/h3c6naam5t1pKbFYDNft1/c1iIiIDGr9fs47lUqRyWR6\nv3ZdF8s6/j5DX8ejlSv1yR/1yT/1yh/1yT/16tTr91fef/AHf0BLSwsAv/vd7xinqwtFREROivE8\nr1/fCn/k1eYAS5cu5eyzz+7PPykiIjKo9Xt4i4iIyKnV74fNRURE5NRSeIuIiESMwltERCRiFN4i\nIiIRE5rBJFoDvW9mzpxJKpUCYNSoUXznO98JuKJw2bx5M3/3d3/HqlWreOutt7jzzjuxLIvGxkbu\nueeeoMsLjSP79NJLL3HrrbfS0NAAwKxZs5g+fXqwBYZAsVjkrrvuYvfu3RQKBebPn8+5556r59T7\nHK1PI0aM0HPqKFzXZfHixbzxxhtYlsW9995LIpHo03MqNOF95BromzdvZunSpaxYsSLoskIpn88D\n8NBDDwVcSTitXLmSxx9/nOrqaqD09sSFCxcydepU7rnnHtavX8+0adMCrjJ47+/T1q1bufnmm7np\nppuCLSxknnjiCYYOHcp3v/td2tvbueqqq/jYxz6m59T7HNmnw4cPc/XVV/PFL35Rz6mj+OUvf4kx\nhkceeYTnn3+ev//7v8fzvD49p0Jz2FxroPu3Y8cOstks8+bN46abbmLz5s1BlxQqY8aM4YEHHuj9\netu2bUydOhWA5uZmNmzYEFRpoXK0Pj3zzDPMmTOHu+++m2w2G2B14TF9+nQWLFgAgOM42LbN9u3b\n9Zx6nyP75LousViMbdu28fTTT+s59T7Tpk3jW9/6FgB79uxhyJAhfX5OhSa8tQa6f5WVlcybN4/v\nf//7fPOb3+SrX/2qenWEyy+/HNu2e78+cimD6upqOjo6gigrdN7fp0mTJvG1r32N1atXM3r0aP7p\nn/4pwOrCo6qqimQySTqdZsGCBXzlK1/Rc+oo3t+nL3/5y3z84x9n0aJFek4dhWVZfP3rX2fJkiX8\nxV/8RZ+fU6EJ7xNdA70cNTQ08JnPfKb3dl1dHa2trQFXFV5HPo8ymQy1tbUBVhNe06ZNY8KECUAp\n2Hfs2BFwReGxd+9ebrzxRmbMmMGVV16p59SHeH+f9Jw6tqVLl/Kzn/2MxYsXk8vlerf7eU6FJh21\nBrp/69atY9myZQDs27ePTCZDfX19wFWF14QJE9i4cSMAzz77LFOmTAm4onC65ZZbePHFFwHYsGED\n5513XsAVhUNbWxvz5s3jjjvuYMaMGQCMHz9ez6n3OVqf9Jw6up/85Cc8+OCDAFRUVGBZFhMnTuT5\n558H/D2nQrM8qtZA9+/IqzqNMXz1q1/l/PPPD7qsUNm9eze33347jz76KG+++Sbf+MY3KBQKjB07\nliVLlmCMCbrEUDiyTzt27ODee+8lHo9TX1/Pfffd13sxWzn79re/zVNPPcU555yD53kYY7j77rtZ\nsmSJnlNHOFqfbr/9dpYtW6bn1Pt0dXVx55130tbWRrFY5NZbb+Wcc85h8eLFvp9ToQlvERER8Sc0\nh81FRETEH4W3iIhIxCi8RUREIkbhLSIiEjEKbxERkYhReIuIiESMwltERCRi/j+ZbHIydBRxGgAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x148a89518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hold(True)\n",
    "for eigvals in load('data/{0}/'.format(experiment_number), which='eigvals'):\n",
    "    plt.plot(eigvals[:30])\n",
    "    \n",
    "plt.hold(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: alpha_0_00000001_eigvals.npy,alpha_0_00000003_eigvals.npy,alpha_0_0000001_eigvals.npy,alpha_0_0000003_eigvals.npy,alpha_0_000001_eigvals.npy,alpha_0_000003_eigvals.npy, from data/1456811360/\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFVCAYAAADCLbfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYkSKm0REZEoodIWERGJEv8//m1FG5Yj5n0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1120a30f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 10)\n",
    "plt.hold(True)\n",
    "for eigvals in load('data/{0}/'.format(experiment_number), which='eigvals'):\n",
    "    plt.plot(eigvals / eigvals.sum())\n",
    "plt.hold(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H, eigvals = hiddenTargets(gram(X), np.outer(y, y), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08984533984533985"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On alpha = 0\n",
    "model = LogisticRegression(C=1e6)\n",
    "model.fit(H, y)\n",
    "(model.predict(H) != y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.089743589743589744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On raw training data\n",
    "model = LogisticRegression(C=1e6)\n",
    "model.fit(X, y)\n",
    "(model.predict(X) != y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: alpha_0_000000000010_H.npy,alpha_0_000000000030_H.npy,alpha_0_000000000100_H.npy,alpha_0_000000000300_H.npy,alpha_0_000000001000_H.npy,alpha_0_000000003000_H.npy,alpha_0_00000001_H.npy,alpha_0_00000003_H.npy,alpha_0_0000001_H.npy,alpha_0_0000003_H.npy,alpha_0_000001_H.npy,alpha_0_000003_H.npy,alpha_0_000010_H.npy,alpha_0_000030_H.npy,alpha_0_000100_H.npy,alpha_0_000300_H.npy,alpha_0_001000_H.npy,alpha_0_003000_H.npy,alpha_0_010000_H.npy,alpha_0_030000_H.npy, from data/mnist_1456811360/\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n",
      "(11982, 613)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "error_train = []\n",
    "for H in load('data/{0}/'.format(experiment_number), which='H'):\n",
    "    print(H.shape)\n",
    "    model = LogisticRegression(C=1e6)\n",
    "    model.fit(H, y)\n",
    "    error_train.append((model.predict(H) != y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained logistic regression on (H, y) for different $\\alpha$. The following are the error rates.\n",
    "![asdf](figures/error_alpha_mnist.png)\n",
    "\n",
    "On a harder training set where we have background images these are the error rates. Base error on raw training set (X, y) was 9%.\n",
    "![asdf](figures/error_alpha_background.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFxCAYAAADjx9tHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149a7bba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(alphas[:12], error_train[:12])\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('Error rate')\n",
    "plt.title('MNIST, logistic regression error rate')\n",
    "plt.savefig('figures/error_alpha_mnist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedule Rob\n",
    "Mondays: Anytime\n",
    "Wednesdays: anytime. \n",
    "Thursdays: 12:30 - 1:45, 3:30 - 4:45\n",
    "Fridays: After surfing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt at model.\n",
    "Each layer is affine - relu - affine\n",
    "\n",
    "Gradient check the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.nets import AffineReluAffineNet\n",
    "from models.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from models.solver import Solver\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'models.layer_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-37a2938c6a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This needs to be modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maffine_relu_affine_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_relu_affine_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'models.layer_utils'"
     ]
    }
   ],
   "source": [
    "# This needs to be modified.\n",
    "\n",
    "from models.layer_utils import affine_relu_affine_forward, affine_relu_affine_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w1 = np.random.randn(12, 10)\n",
    "w2 = np.random.randn(10, 10)\n",
    "b1 = np.random.randn(10)\n",
    "b2 = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_affine_forward(x, w1, b1, w2, b2)\n",
    "dx, dw1, db1, dw2, db2 = affine_relu_affine_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: affine_relu_affine_forward(x, w1, b1, w2, b2)[0]\n",
    "fw1 = lambda w1: affine_relu_affine_forward(x, w1, b1, w2, b2)[0]\n",
    "fb1 = lambda b1: affine_relu_affine_forward(x, w1, b1, w2, b2)[0]\n",
    "fw2 = lambda w2: affine_relu_affine_forward(x, w1, b1, w2, b2)[0]\n",
    "fb2 = lambda b2: affine_relu_affine_forward(x, w1, b1, w2, b2)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dw1_num = eval_numerical_gradient_array(fw1, w1, dout)\n",
    "db1_num = eval_numerical_gradient_array(fb1, b1, dout)\n",
    "dw2_num = eval_numerical_gradient_array(fw2, w2, dout)\n",
    "db2_num = eval_numerical_gradient_array(fb2, b2, dout)\n",
    "\n",
    "print ('Testing affine_relu_affine_forward:')\n",
    "print ('dx error: ', rel_error(dx_num, dx))\n",
    "print ('dw1 error: ', rel_error(dw1_num, dw1))\n",
    "print ('db1 error: ', rel_error(db1_num, db1))\n",
    "print ('dw2 error: ', rel_error(dw2_num, dw2))\n",
    "print ('db2 error: ', rel_error(db2_num, db2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071428571428571425"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_scale = 2 / np.sqrt(28*28)\n",
    "init_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32091041667\n"
     ]
    }
   ],
   "source": [
    "model = AffineReluAffineNet(hidden_dims=[30, 30, 30], \n",
    "                          input_dim=28*28, \n",
    "                          num_classes=10, \n",
    "                          reg=0, \n",
    "                          weight_scale=init_scale)\n",
    "\n",
    "loss, grads = model.loss(X_data, y_data)\n",
    "print(loss)  # Should be around 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721.671577886\n"
     ]
    }
   ],
   "source": [
    "model = AffineReluAffineNet(hidden_dims=[30, 30, 30], \n",
    "                          input_dim=28*28, \n",
    "                          num_classes=10, \n",
    "                          reg=10, \n",
    "                          weight_scale=init_scale)\n",
    "\n",
    "\n",
    "loss, grads = model.loss(X_data, y_data)\n",
    "print(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217.11880437\n",
      "3265.48949562\n"
     ]
    }
   ],
   "source": [
    "submodel = model[0]\n",
    "\n",
    "X_r = np.random.rand(100, 28*28)\n",
    "y_r = 0.1 * np.random.randn(100, 30) - 10\n",
    "X_rval = np.random.rand(10, 28*28)\n",
    "y_rval = 0.1 * np.random.randn(10, 30) + 10\n",
    "l, gr = submodel.loss(X_r, y_r)\n",
    "print(l)\n",
    "l, gr = submodel.loss(X_rval, y_rval)\n",
    "print(l)\n",
    "data = {'X_train': X_r, 'y_train': y_r, 'X_val': X_rval, 'y_val': y_rval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1000) loss: 1218.766400\n",
      "(Epoch 1 / 1000) train loss: 1159.933445; val_loss: 3390.851256\n",
      "(Epoch 2 / 1000) train loss: 1106.376679; val_loss: 3517.899100\n",
      "(Epoch 3 / 1000) train loss: 1056.500476; val_loss: 3645.975878\n",
      "(Epoch 4 / 1000) train loss: 1010.299417; val_loss: 3774.396125\n",
      "(Epoch 5 / 1000) train loss: 967.726936; val_loss: 3902.432315\n",
      "(Epoch 6 / 1000) train loss: 928.689824; val_loss: 4029.388154\n",
      "(Epoch 7 / 1000) train loss: 893.058712; val_loss: 4154.554071\n",
      "(Epoch 8 / 1000) train loss: 860.673801; val_loss: 4277.270521\n",
      "(Epoch 9 / 1000) train loss: 831.352022; val_loss: 4396.857926\n",
      "(Epoch 10 / 1000) train loss: 804.891401; val_loss: 4512.634139\n",
      "(Epoch 11 / 1000) train loss: 781.072247; val_loss: 4623.989731\n",
      "(Epoch 12 / 1000) train loss: 759.667432; val_loss: 4730.449406\n",
      "(Epoch 13 / 1000) train loss: 740.449569; val_loss: 4831.543815\n",
      "(Epoch 14 / 1000) train loss: 723.193783; val_loss: 4927.052261\n",
      "(Epoch 15 / 1000) train loss: 707.690360; val_loss: 5016.733520\n",
      "(Epoch 16 / 1000) train loss: 693.738173; val_loss: 5100.494436\n",
      "(Epoch 17 / 1000) train loss: 681.156375; val_loss: 5178.256821\n",
      "(Epoch 18 / 1000) train loss: 669.782775; val_loss: 5249.984887\n",
      "(Epoch 19 / 1000) train loss: 659.470572; val_loss: 5315.833145\n",
      "(Epoch 20 / 1000) train loss: 650.088780; val_loss: 5375.993177\n",
      "(Epoch 21 / 1000) train loss: 641.525426; val_loss: 5430.718296\n",
      "(Epoch 22 / 1000) train loss: 633.680414; val_loss: 5480.320772\n",
      "(Epoch 23 / 1000) train loss: 626.471888; val_loss: 5525.195717\n",
      "(Epoch 24 / 1000) train loss: 619.827970; val_loss: 5565.587332\n",
      "(Epoch 25 / 1000) train loss: 613.685729; val_loss: 5601.844789\n",
      "(Epoch 26 / 1000) train loss: 607.992185; val_loss: 5634.275234\n",
      "(Epoch 27 / 1000) train loss: 602.700044; val_loss: 5663.093836\n",
      "(Epoch 28 / 1000) train loss: 597.770876; val_loss: 5688.673641\n",
      "(Epoch 29 / 1000) train loss: 593.170781; val_loss: 5711.381854\n",
      "(Epoch 30 / 1000) train loss: 588.870087; val_loss: 5731.505106\n",
      "(Epoch 31 / 1000) train loss: 584.843864; val_loss: 5749.187977\n",
      "(Epoch 32 / 1000) train loss: 581.069193; val_loss: 5764.660582\n",
      "(Epoch 33 / 1000) train loss: 577.526739; val_loss: 5778.219188\n",
      "(Epoch 34 / 1000) train loss: 574.199493; val_loss: 5790.049164\n",
      "(Epoch 35 / 1000) train loss: 571.073061; val_loss: 5800.453299\n",
      "(Epoch 36 / 1000) train loss: 568.133189; val_loss: 5809.597104\n",
      "(Epoch 37 / 1000) train loss: 565.366286; val_loss: 5817.591392\n",
      "(Epoch 38 / 1000) train loss: 562.761187; val_loss: 5824.677604\n",
      "(Epoch 39 / 1000) train loss: 560.306944; val_loss: 5830.857391\n",
      "(Epoch 40 / 1000) train loss: 557.995596; val_loss: 5836.335182\n",
      "(Epoch 41 / 1000) train loss: 555.816970; val_loss: 5841.116924\n",
      "(Epoch 42 / 1000) train loss: 553.763114; val_loss: 5845.248684\n",
      "(Epoch 43 / 1000) train loss: 551.826306; val_loss: 5848.925435\n",
      "(Epoch 44 / 1000) train loss: 549.999060; val_loss: 5852.175364\n",
      "(Epoch 45 / 1000) train loss: 548.274698; val_loss: 5855.053904\n",
      "(Epoch 46 / 1000) train loss: 546.647136; val_loss: 5857.599484\n",
      "(Epoch 47 / 1000) train loss: 545.109914; val_loss: 5859.865883\n",
      "(Epoch 48 / 1000) train loss: 543.657530; val_loss: 5861.882585\n",
      "(Epoch 49 / 1000) train loss: 542.285129; val_loss: 5863.667037\n",
      "(Epoch 50 / 1000) train loss: 540.988483; val_loss: 5865.228296\n",
      "(Epoch 51 / 1000) train loss: 539.762763; val_loss: 5866.619271\n",
      "(Epoch 52 / 1000) train loss: 538.603949; val_loss: 5867.887225\n",
      "(Epoch 53 / 1000) train loss: 537.508150; val_loss: 5869.035644\n",
      "(Epoch 54 / 1000) train loss: 536.471785; val_loss: 5870.089419\n",
      "(Epoch 55 / 1000) train loss: 535.491260; val_loss: 5871.046394\n",
      "(Epoch 56 / 1000) train loss: 534.563395; val_loss: 5871.943092\n",
      "(Epoch 57 / 1000) train loss: 533.685154; val_loss: 5872.740175\n",
      "(Epoch 58 / 1000) train loss: 532.853705; val_loss: 5873.453982\n",
      "(Epoch 59 / 1000) train loss: 532.066400; val_loss: 5874.125236\n",
      "(Epoch 60 / 1000) train loss: 531.320670; val_loss: 5874.737667\n",
      "(Epoch 61 / 1000) train loss: 530.614243; val_loss: 5875.304367\n",
      "(Epoch 62 / 1000) train loss: 529.944994; val_loss: 5875.861142\n",
      "(Epoch 63 / 1000) train loss: 529.310831; val_loss: 5876.381006\n",
      "(Epoch 64 / 1000) train loss: 528.709763; val_loss: 5876.872917\n",
      "(Epoch 65 / 1000) train loss: 528.139868; val_loss: 5877.339903\n",
      "(Epoch 66 / 1000) train loss: 527.599462; val_loss: 5877.783698\n",
      "(Epoch 67 / 1000) train loss: 527.086957; val_loss: 5878.211200\n",
      "(Epoch 68 / 1000) train loss: 526.600858; val_loss: 5878.608646\n",
      "(Epoch 69 / 1000) train loss: 526.139795; val_loss: 5878.985531\n",
      "(Epoch 70 / 1000) train loss: 525.702361; val_loss: 5879.355349\n",
      "(Epoch 71 / 1000) train loss: 525.287304; val_loss: 5879.712129\n",
      "(Epoch 72 / 1000) train loss: 524.893471; val_loss: 5880.048269\n",
      "(Epoch 73 / 1000) train loss: 524.519643; val_loss: 5880.356867\n",
      "(Epoch 74 / 1000) train loss: 524.164831; val_loss: 5880.664704\n",
      "(Epoch 75 / 1000) train loss: 523.827927; val_loss: 5880.967898\n",
      "(Epoch 76 / 1000) train loss: 523.508065; val_loss: 5881.265288\n",
      "(Epoch 77 / 1000) train loss: 523.204366; val_loss: 5881.540947\n",
      "(Epoch 78 / 1000) train loss: 522.916020; val_loss: 5881.805688\n",
      "(Epoch 79 / 1000) train loss: 522.642094; val_loss: 5882.079678\n",
      "(Epoch 80 / 1000) train loss: 522.381959; val_loss: 5882.337773\n",
      "(Epoch 81 / 1000) train loss: 522.134873; val_loss: 5882.584331\n",
      "(Epoch 82 / 1000) train loss: 521.900216; val_loss: 5882.827218\n",
      "(Epoch 83 / 1000) train loss: 521.677263; val_loss: 5883.060644\n",
      "(Epoch 84 / 1000) train loss: 521.465405; val_loss: 5883.282458\n",
      "(Epoch 85 / 1000) train loss: 521.264169; val_loss: 5883.493325\n",
      "(Epoch 86 / 1000) train loss: 521.072955; val_loss: 5883.692870\n",
      "(Epoch 87 / 1000) train loss: 520.891292; val_loss: 5883.887210\n",
      "(Epoch 88 / 1000) train loss: 520.718618; val_loss: 5884.075883\n",
      "(Epoch 89 / 1000) train loss: 520.554568; val_loss: 5884.261997\n",
      "(Epoch 90 / 1000) train loss: 520.398634; val_loss: 5884.435173\n",
      "(Epoch 91 / 1000) train loss: 520.250465; val_loss: 5884.605751\n",
      "(Epoch 92 / 1000) train loss: 520.109626; val_loss: 5884.768446\n",
      "(Epoch 93 / 1000) train loss: 519.975750; val_loss: 5884.928353\n",
      "(Epoch 94 / 1000) train loss: 519.848464; val_loss: 5885.087077\n",
      "(Epoch 95 / 1000) train loss: 519.727479; val_loss: 5885.238419\n",
      "(Epoch 96 / 1000) train loss: 519.612520; val_loss: 5885.385746\n",
      "(Epoch 97 / 1000) train loss: 519.503208; val_loss: 5885.524246\n",
      "(Epoch 98 / 1000) train loss: 519.399298; val_loss: 5885.656248\n",
      "(Epoch 99 / 1000) train loss: 519.300503; val_loss: 5885.781988\n",
      "(Epoch 100 / 1000) train loss: 519.206618; val_loss: 5885.900959\n",
      "(Iteration 101 / 1000) loss: 518.711650\n",
      "(Epoch 101 / 1000) train loss: 519.117365; val_loss: 5886.011531\n",
      "(Epoch 102 / 1000) train loss: 519.032494; val_loss: 5886.119657\n",
      "(Epoch 103 / 1000) train loss: 518.951793; val_loss: 5886.221506\n",
      "(Epoch 104 / 1000) train loss: 518.875065; val_loss: 5886.317215\n",
      "(Epoch 105 / 1000) train loss: 518.802147; val_loss: 5886.408423\n",
      "(Epoch 106 / 1000) train loss: 518.732847; val_loss: 5886.498217\n",
      "(Epoch 107 / 1000) train loss: 518.666845; val_loss: 5886.582999\n",
      "(Epoch 108 / 1000) train loss: 518.604170; val_loss: 5886.662368\n",
      "(Epoch 109 / 1000) train loss: 518.544576; val_loss: 5886.740448\n",
      "(Epoch 110 / 1000) train loss: 518.487874; val_loss: 5886.818607\n",
      "(Epoch 111 / 1000) train loss: 518.434023; val_loss: 5886.891792\n",
      "(Epoch 112 / 1000) train loss: 518.382760; val_loss: 5886.959835\n",
      "(Epoch 113 / 1000) train loss: 518.334046; val_loss: 5887.024978\n",
      "(Epoch 114 / 1000) train loss: 518.287742; val_loss: 5887.087986\n",
      "(Epoch 115 / 1000) train loss: 518.243679; val_loss: 5887.147754\n",
      "(Epoch 116 / 1000) train loss: 518.201784; val_loss: 5887.203592\n",
      "(Epoch 117 / 1000) train loss: 518.161949; val_loss: 5887.256172\n",
      "(Epoch 118 / 1000) train loss: 518.124078; val_loss: 5887.307660\n",
      "(Epoch 119 / 1000) train loss: 518.088071; val_loss: 5887.355196\n",
      "(Epoch 120 / 1000) train loss: 518.053831; val_loss: 5887.400909\n",
      "(Epoch 121 / 1000) train loss: 518.021250; val_loss: 5887.444631\n",
      "(Epoch 122 / 1000) train loss: 517.990319; val_loss: 5887.485808\n",
      "(Epoch 123 / 1000) train loss: 517.960879; val_loss: 5887.523904\n",
      "(Epoch 124 / 1000) train loss: 517.932880; val_loss: 5887.560756\n",
      "(Epoch 125 / 1000) train loss: 517.906292; val_loss: 5887.595763\n",
      "(Epoch 126 / 1000) train loss: 517.880953; val_loss: 5887.629665\n",
      "(Epoch 127 / 1000) train loss: 517.856898; val_loss: 5887.661801\n",
      "(Epoch 128 / 1000) train loss: 517.833975; val_loss: 5887.691597\n",
      "(Epoch 129 / 1000) train loss: 517.812225; val_loss: 5887.719885\n",
      "(Epoch 130 / 1000) train loss: 517.791541; val_loss: 5887.746799\n",
      "(Epoch 131 / 1000) train loss: 517.771853; val_loss: 5887.772589\n",
      "(Epoch 132 / 1000) train loss: 517.753181; val_loss: 5887.797069\n",
      "(Epoch 133 / 1000) train loss: 517.735387; val_loss: 5887.819936\n",
      "(Epoch 134 / 1000) train loss: 517.718481; val_loss: 5887.843231\n",
      "(Epoch 135 / 1000) train loss: 517.702395; val_loss: 5887.865883\n",
      "(Epoch 136 / 1000) train loss: 517.687090; val_loss: 5887.886382\n",
      "(Epoch 137 / 1000) train loss: 517.672549; val_loss: 5887.905118\n",
      "(Epoch 138 / 1000) train loss: 517.658727; val_loss: 5887.923299\n",
      "(Epoch 139 / 1000) train loss: 517.645610; val_loss: 5887.940614\n",
      "(Epoch 140 / 1000) train loss: 517.633119; val_loss: 5887.958176\n",
      "(Epoch 141 / 1000) train loss: 517.621233; val_loss: 5887.974204\n",
      "(Epoch 142 / 1000) train loss: 517.609939; val_loss: 5887.990499\n",
      "(Epoch 143 / 1000) train loss: 517.599181; val_loss: 5888.005905\n",
      "(Epoch 144 / 1000) train loss: 517.588964; val_loss: 5888.020697\n",
      "(Epoch 145 / 1000) train loss: 517.579234; val_loss: 5888.035561\n",
      "(Epoch 146 / 1000) train loss: 517.570023; val_loss: 5888.049839\n",
      "(Epoch 147 / 1000) train loss: 517.561213; val_loss: 5888.063117\n",
      "(Epoch 148 / 1000) train loss: 517.552867; val_loss: 5888.075474\n",
      "(Epoch 149 / 1000) train loss: 517.544925; val_loss: 5888.087666\n",
      "(Epoch 150 / 1000) train loss: 517.537361; val_loss: 5888.098772\n",
      "(Epoch 151 / 1000) train loss: 517.530223; val_loss: 5888.109194\n",
      "(Epoch 152 / 1000) train loss: 517.523377; val_loss: 5888.119505\n",
      "(Epoch 153 / 1000) train loss: 517.516910; val_loss: 5888.129381\n",
      "(Epoch 154 / 1000) train loss: 517.510725; val_loss: 5888.138821\n",
      "(Epoch 155 / 1000) train loss: 517.504890; val_loss: 5888.147495\n",
      "(Epoch 156 / 1000) train loss: 517.499292; val_loss: 5888.155925\n",
      "(Epoch 157 / 1000) train loss: 517.493997; val_loss: 5888.163895\n",
      "(Epoch 158 / 1000) train loss: 517.488957; val_loss: 5888.171207\n",
      "(Epoch 159 / 1000) train loss: 517.484155; val_loss: 5888.178362\n",
      "(Epoch 160 / 1000) train loss: 517.479602; val_loss: 5888.185106\n",
      "(Epoch 161 / 1000) train loss: 517.475283; val_loss: 5888.191670\n",
      "(Epoch 162 / 1000) train loss: 517.471153; val_loss: 5888.197997\n",
      "(Epoch 163 / 1000) train loss: 517.467244; val_loss: 5888.204066\n",
      "(Epoch 164 / 1000) train loss: 517.463515; val_loss: 5888.209786\n",
      "(Epoch 165 / 1000) train loss: 517.459961; val_loss: 5888.215136\n",
      "(Epoch 166 / 1000) train loss: 517.456583; val_loss: 5888.220179\n",
      "(Epoch 167 / 1000) train loss: 517.453408; val_loss: 5888.225042\n",
      "(Epoch 168 / 1000) train loss: 517.450383; val_loss: 5888.229657\n",
      "(Epoch 169 / 1000) train loss: 517.447454; val_loss: 5888.233890\n",
      "(Epoch 170 / 1000) train loss: 517.444753; val_loss: 5888.237916\n",
      "(Epoch 171 / 1000) train loss: 517.442125; val_loss: 5888.241704\n",
      "(Epoch 172 / 1000) train loss: 517.439642; val_loss: 5888.245287\n",
      "(Epoch 173 / 1000) train loss: 517.437260; val_loss: 5888.248609\n",
      "(Epoch 174 / 1000) train loss: 517.435026; val_loss: 5888.251712\n",
      "(Epoch 175 / 1000) train loss: 517.432880; val_loss: 5888.254645\n",
      "(Epoch 176 / 1000) train loss: 517.430869; val_loss: 5888.257594\n",
      "(Epoch 177 / 1000) train loss: 517.428951; val_loss: 5888.260452\n",
      "(Epoch 178 / 1000) train loss: 517.427084; val_loss: 5888.263068\n",
      "(Epoch 179 / 1000) train loss: 517.425379; val_loss: 5888.265690\n",
      "(Epoch 180 / 1000) train loss: 517.423721; val_loss: 5888.268179\n",
      "(Epoch 181 / 1000) train loss: 517.422100; val_loss: 5888.270666\n",
      "(Epoch 182 / 1000) train loss: 517.420644; val_loss: 5888.272977\n",
      "(Epoch 183 / 1000) train loss: 517.419221; val_loss: 5888.275158\n",
      "(Epoch 184 / 1000) train loss: 517.417876; val_loss: 5888.277306\n",
      "(Epoch 185 / 1000) train loss: 517.416569; val_loss: 5888.279297\n",
      "(Epoch 186 / 1000) train loss: 517.415371; val_loss: 5888.281170\n",
      "(Epoch 187 / 1000) train loss: 517.414167; val_loss: 5888.282987\n",
      "(Epoch 188 / 1000) train loss: 517.413072; val_loss: 5888.284540\n",
      "(Epoch 189 / 1000) train loss: 517.412003; val_loss: 5888.286079\n",
      "(Epoch 190 / 1000) train loss: 517.411003; val_loss: 5888.287625\n",
      "(Epoch 191 / 1000) train loss: 517.410070; val_loss: 5888.289105\n",
      "(Epoch 192 / 1000) train loss: 517.409159; val_loss: 5888.290373\n",
      "(Epoch 193 / 1000) train loss: 517.408280; val_loss: 5888.291619\n",
      "(Epoch 194 / 1000) train loss: 517.407493; val_loss: 5888.292926\n",
      "(Epoch 195 / 1000) train loss: 517.406729; val_loss: 5888.294278\n",
      "(Epoch 196 / 1000) train loss: 517.405981; val_loss: 5888.295335\n",
      "(Epoch 197 / 1000) train loss: 517.405257; val_loss: 5888.296421\n",
      "(Epoch 198 / 1000) train loss: 517.404593; val_loss: 5888.297417\n",
      "(Epoch 199 / 1000) train loss: 517.403987; val_loss: 5888.298392\n",
      "(Epoch 200 / 1000) train loss: 517.403398; val_loss: 5888.299179\n",
      "(Iteration 201 / 1000) loss: 516.783479\n",
      "(Epoch 201 / 1000) train loss: 517.402820; val_loss: 5888.300007\n",
      "(Epoch 202 / 1000) train loss: 517.402256; val_loss: 5888.300900\n",
      "(Epoch 203 / 1000) train loss: 517.401740; val_loss: 5888.301734\n",
      "(Epoch 204 / 1000) train loss: 517.401239; val_loss: 5888.302526\n",
      "(Epoch 205 / 1000) train loss: 517.400794; val_loss: 5888.303260\n",
      "(Epoch 206 / 1000) train loss: 517.400365; val_loss: 5888.303935\n",
      "(Epoch 207 / 1000) train loss: 517.399907; val_loss: 5888.304492\n",
      "(Epoch 208 / 1000) train loss: 517.399536; val_loss: 5888.305197\n",
      "(Epoch 209 / 1000) train loss: 517.399102; val_loss: 5888.305618\n",
      "(Epoch 210 / 1000) train loss: 517.398757; val_loss: 5888.306207\n",
      "(Epoch 211 / 1000) train loss: 517.398418; val_loss: 5888.306673\n",
      "(Epoch 212 / 1000) train loss: 517.398092; val_loss: 5888.307156\n",
      "(Epoch 213 / 1000) train loss: 517.397809; val_loss: 5888.307696\n",
      "(Epoch 214 / 1000) train loss: 517.397537; val_loss: 5888.308184\n",
      "(Epoch 215 / 1000) train loss: 517.397267; val_loss: 5888.308673\n",
      "(Epoch 216 / 1000) train loss: 517.396966; val_loss: 5888.309035\n",
      "(Epoch 217 / 1000) train loss: 517.396706; val_loss: 5888.309486\n",
      "(Epoch 218 / 1000) train loss: 517.396489; val_loss: 5888.309882\n",
      "(Epoch 219 / 1000) train loss: 517.396207; val_loss: 5888.310245\n",
      "(Epoch 220 / 1000) train loss: 517.396009; val_loss: 5888.310582\n",
      "(Epoch 221 / 1000) train loss: 517.395774; val_loss: 5888.310844\n",
      "(Epoch 222 / 1000) train loss: 517.395556; val_loss: 5888.311040\n",
      "(Epoch 223 / 1000) train loss: 517.395380; val_loss: 5888.311331\n",
      "(Epoch 224 / 1000) train loss: 517.395208; val_loss: 5888.311672\n",
      "(Epoch 225 / 1000) train loss: 517.395038; val_loss: 5888.311879\n",
      "(Epoch 226 / 1000) train loss: 517.394872; val_loss: 5888.312122\n",
      "(Epoch 227 / 1000) train loss: 517.394713; val_loss: 5888.312337\n",
      "(Epoch 228 / 1000) train loss: 517.394558; val_loss: 5888.312596\n",
      "(Epoch 229 / 1000) train loss: 517.394447; val_loss: 5888.312803\n",
      "(Epoch 230 / 1000) train loss: 517.394302; val_loss: 5888.312982\n",
      "(Epoch 231 / 1000) train loss: 517.394164; val_loss: 5888.313061\n",
      "(Epoch 232 / 1000) train loss: 517.394061; val_loss: 5888.313339\n",
      "(Epoch 233 / 1000) train loss: 517.393962; val_loss: 5888.313656\n",
      "(Epoch 234 / 1000) train loss: 517.393861; val_loss: 5888.313858\n",
      "(Epoch 235 / 1000) train loss: 517.393727; val_loss: 5888.314059\n",
      "(Epoch 236 / 1000) train loss: 517.393673; val_loss: 5888.314269\n",
      "(Epoch 237 / 1000) train loss: 517.393546; val_loss: 5888.314505\n",
      "(Epoch 238 / 1000) train loss: 517.393459; val_loss: 5888.314692\n",
      "(Epoch 239 / 1000) train loss: 517.393412; val_loss: 5888.314927\n",
      "(Epoch 240 / 1000) train loss: 517.393330; val_loss: 5888.315126\n",
      "(Epoch 241 / 1000) train loss: 517.393209; val_loss: 5888.315207\n",
      "(Epoch 242 / 1000) train loss: 517.393171; val_loss: 5888.315512\n",
      "(Epoch 243 / 1000) train loss: 517.393100; val_loss: 5888.315622\n",
      "(Epoch 244 / 1000) train loss: 517.393074; val_loss: 5888.315779\n",
      "(Epoch 245 / 1000) train loss: 517.393010; val_loss: 5888.315922\n",
      "(Epoch 246 / 1000) train loss: 517.392982; val_loss: 5888.316106\n",
      "(Epoch 247 / 1000) train loss: 517.392957; val_loss: 5888.316265\n",
      "(Epoch 248 / 1000) train loss: 517.392934; val_loss: 5888.316461\n",
      "(Epoch 249 / 1000) train loss: 517.392910; val_loss: 5888.316676\n",
      "(Epoch 250 / 1000) train loss: 517.392889; val_loss: 5888.316813\n",
      "(Epoch 251 / 1000) train loss: 517.392867; val_loss: 5888.316995\n",
      "(Epoch 252 / 1000) train loss: 517.392808; val_loss: 5888.317096\n",
      "(Epoch 253 / 1000) train loss: 517.392790; val_loss: 5888.317256\n",
      "(Epoch 254 / 1000) train loss: 517.392735; val_loss: 5888.317338\n",
      "(Epoch 255 / 1000) train loss: 517.392756; val_loss: 5888.317520\n",
      "(Epoch 256 / 1000) train loss: 517.392704; val_loss: 5888.317589\n",
      "(Epoch 257 / 1000) train loss: 517.392692; val_loss: 5888.317678\n",
      "(Epoch 258 / 1000) train loss: 517.392683; val_loss: 5888.317752\n",
      "(Epoch 259 / 1000) train loss: 517.392674; val_loss: 5888.317805\n",
      "(Epoch 260 / 1000) train loss: 517.392667; val_loss: 5888.317866\n",
      "(Epoch 261 / 1000) train loss: 517.392659; val_loss: 5888.317949\n",
      "(Epoch 262 / 1000) train loss: 517.392650; val_loss: 5888.318006\n",
      "(Epoch 263 / 1000) train loss: 517.392644; val_loss: 5888.318055\n",
      "(Epoch 264 / 1000) train loss: 517.392637; val_loss: 5888.318112\n",
      "(Epoch 265 / 1000) train loss: 517.392631; val_loss: 5888.318177\n",
      "(Epoch 266 / 1000) train loss: 517.392625; val_loss: 5888.318232\n",
      "(Epoch 267 / 1000) train loss: 517.392619; val_loss: 5888.318271\n",
      "(Epoch 268 / 1000) train loss: 517.392614; val_loss: 5888.318303\n",
      "(Epoch 269 / 1000) train loss: 517.392610; val_loss: 5888.318329\n",
      "(Epoch 270 / 1000) train loss: 517.392606; val_loss: 5888.318363\n",
      "(Epoch 271 / 1000) train loss: 517.392603; val_loss: 5888.318395\n",
      "(Epoch 272 / 1000) train loss: 517.392600; val_loss: 5888.318414\n",
      "(Epoch 273 / 1000) train loss: 517.392599; val_loss: 5888.318431\n",
      "(Epoch 274 / 1000) train loss: 517.392596; val_loss: 5888.318458\n",
      "(Epoch 275 / 1000) train loss: 517.392594; val_loss: 5888.318464\n",
      "(Epoch 276 / 1000) train loss: 517.392592; val_loss: 5888.318490\n",
      "(Epoch 277 / 1000) train loss: 517.392590; val_loss: 5888.318516\n",
      "(Epoch 278 / 1000) train loss: 517.392588; val_loss: 5888.318548\n",
      "(Epoch 279 / 1000) train loss: 517.392586; val_loss: 5888.318565\n",
      "(Epoch 280 / 1000) train loss: 517.392585; val_loss: 5888.318567\n",
      "(Epoch 281 / 1000) train loss: 517.392583; val_loss: 5888.318581\n",
      "(Epoch 282 / 1000) train loss: 517.392582; val_loss: 5888.318583\n",
      "(Epoch 283 / 1000) train loss: 517.392580; val_loss: 5888.318578\n",
      "(Epoch 284 / 1000) train loss: 517.392580; val_loss: 5888.318583\n",
      "(Epoch 285 / 1000) train loss: 517.392579; val_loss: 5888.318590\n",
      "(Epoch 286 / 1000) train loss: 517.392578; val_loss: 5888.318591\n",
      "(Epoch 287 / 1000) train loss: 517.392578; val_loss: 5888.318589\n",
      "(Epoch 288 / 1000) train loss: 517.392577; val_loss: 5888.318600\n",
      "(Epoch 289 / 1000) train loss: 517.392577; val_loss: 5888.318613\n",
      "(Epoch 290 / 1000) train loss: 517.392576; val_loss: 5888.318626\n",
      "(Epoch 291 / 1000) train loss: 517.392575; val_loss: 5888.318627\n",
      "(Epoch 292 / 1000) train loss: 517.392575; val_loss: 5888.318631\n",
      "(Epoch 293 / 1000) train loss: 517.392575; val_loss: 5888.318630\n",
      "(Epoch 294 / 1000) train loss: 517.392574; val_loss: 5888.318634\n",
      "(Epoch 295 / 1000) train loss: 517.392574; val_loss: 5888.318634\n",
      "(Epoch 296 / 1000) train loss: 517.392573; val_loss: 5888.318637\n",
      "(Epoch 297 / 1000) train loss: 517.392573; val_loss: 5888.318637\n",
      "(Epoch 298 / 1000) train loss: 517.392573; val_loss: 5888.318639\n",
      "(Epoch 299 / 1000) train loss: 517.392573; val_loss: 5888.318639\n",
      "(Epoch 300 / 1000) train loss: 517.392573; val_loss: 5888.318642\n",
      "(Iteration 301 / 1000) loss: 516.689792\n",
      "(Epoch 301 / 1000) train loss: 517.392572; val_loss: 5888.318645\n",
      "(Epoch 302 / 1000) train loss: 517.392572; val_loss: 5888.318645\n",
      "(Epoch 303 / 1000) train loss: 517.392572; val_loss: 5888.318645\n",
      "(Epoch 304 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 305 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 306 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 307 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 308 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 309 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 310 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 311 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 312 / 1000) train loss: 517.392572; val_loss: 5888.318646\n",
      "(Epoch 313 / 1000) train loss: 517.392572; val_loss: 5888.318644\n",
      "(Epoch 314 / 1000) train loss: 517.392572; val_loss: 5888.318644\n",
      "(Epoch 315 / 1000) train loss: 517.392572; val_loss: 5888.318644\n",
      "(Epoch 316 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 317 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 318 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 319 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 320 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 321 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 322 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 323 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 324 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 325 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 326 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 327 / 1000) train loss: 517.392571; val_loss: 5888.318644\n",
      "(Epoch 328 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 329 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 330 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 331 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 332 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 333 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 334 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 335 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 336 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 337 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 338 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 339 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 340 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 341 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 342 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 343 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 344 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 345 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 346 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 347 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 348 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 349 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 350 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 351 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 352 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 353 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 354 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 355 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 356 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 357 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 358 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 359 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 360 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 361 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 362 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 363 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 364 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 365 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 366 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 367 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 368 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 369 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 370 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 371 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 372 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 373 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 374 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 375 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 376 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 377 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 378 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 379 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 380 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 381 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 382 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 383 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 384 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 385 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 386 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 387 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 388 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 389 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 390 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 391 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 392 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 393 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 394 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 395 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 396 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 397 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 398 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 399 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 400 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Iteration 401 / 1000) loss: 517.534195\n",
      "(Epoch 401 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 402 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 403 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 404 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 405 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 406 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 407 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 408 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 409 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 410 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 411 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 412 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 413 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 414 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 415 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 416 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 417 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 418 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 419 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 420 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 421 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 422 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 423 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 424 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 425 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 426 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 427 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 428 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 429 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 430 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 431 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 432 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 433 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 434 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 435 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 436 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 437 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 438 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 439 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 440 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 441 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 442 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 443 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 444 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 445 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 446 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 447 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 448 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 449 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 450 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 451 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 452 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 453 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 454 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 455 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 456 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 457 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 458 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 459 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 460 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 461 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 462 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 463 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 464 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 465 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 466 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 467 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 468 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 469 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 470 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 471 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 472 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 473 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 474 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 475 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 476 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 477 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 478 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 479 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 480 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 481 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 482 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 483 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 484 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 485 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 486 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 487 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 488 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 489 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 490 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 491 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 492 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 493 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 494 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 495 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 496 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 497 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 498 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 499 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 500 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Iteration 501 / 1000) loss: 516.703858\n",
      "(Epoch 501 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 502 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 503 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 504 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 505 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 506 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 507 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 508 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 509 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 510 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 511 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 512 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 513 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 514 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 515 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 516 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 517 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 518 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 519 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 520 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 521 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 522 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 523 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 524 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 525 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 526 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 527 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 528 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 529 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 530 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 531 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 532 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 533 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 534 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 535 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 536 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 537 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 538 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 539 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 540 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 541 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 542 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 543 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 544 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 545 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 546 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 547 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 548 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 549 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 550 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 551 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 552 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 553 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 554 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 555 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 556 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 557 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 558 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 559 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 560 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 561 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 562 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 563 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 564 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 565 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 566 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 567 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 568 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 569 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 570 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 571 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 572 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 573 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 574 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 575 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 576 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 577 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 578 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 579 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 580 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 581 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 582 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 583 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 584 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 585 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 586 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 587 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 588 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 589 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 590 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 591 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 592 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 593 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 594 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 595 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 596 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 597 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 598 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 599 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 600 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Iteration 601 / 1000) loss: 516.742053\n",
      "(Epoch 601 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 602 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 603 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 604 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 605 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 606 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 607 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 608 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 609 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 610 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 611 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 612 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 613 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 614 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 615 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 616 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 617 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 618 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 619 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 620 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 621 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 622 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 623 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 624 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 625 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 626 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 627 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 628 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 629 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 630 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 631 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 632 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 633 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 634 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 635 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 636 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 637 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 638 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 639 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 640 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 641 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 642 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 643 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 644 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 645 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 646 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 647 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 648 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 649 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 650 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 651 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 652 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 653 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 654 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 655 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 656 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 657 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 658 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 659 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 660 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 661 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 662 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 663 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 664 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 665 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 666 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 667 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 668 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 669 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 670 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 671 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 672 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 673 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 674 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 675 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 676 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 677 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 678 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 679 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 680 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 681 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 682 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 683 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 684 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 685 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 686 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 687 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 688 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 689 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 690 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 691 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 692 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 693 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 694 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 695 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 696 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 697 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 698 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 699 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 700 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Iteration 701 / 1000) loss: 516.729854\n",
      "(Epoch 701 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 702 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 703 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 704 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 705 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 706 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 707 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 708 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 709 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 710 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 711 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 712 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 713 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 714 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 715 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 716 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 717 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 718 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 719 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 720 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 721 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 722 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 723 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 724 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 725 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 726 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 727 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 728 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 729 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 730 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 731 / 1000) train loss: 517.392571; val_loss: 5888.318646\n",
      "(Epoch 732 / 1000) train loss: 517.392571; val_loss: 5888.318646"
     ]
    }
   ],
   "source": [
    "solver = Solver(submodel, data, classification=False,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                lr_decay=0.95,\n",
    "                num_epochs=1000, batch_size=100,\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 300) loss: 2.301971\n",
      "(Epoch 0 / 30) train acc: 0.137000; val_acc: 0.138525\n",
      "(Epoch 1 / 30) train acc: 0.282000; val_acc: 0.262898\n",
      "(Epoch 2 / 30) train acc: 0.591000; val_acc: 0.554508\n",
      "(Epoch 3 / 30) train acc: 0.680000; val_acc: 0.631915\n",
      "(Epoch 4 / 30) train acc: 0.745000; val_acc: 0.703407\n",
      "(Epoch 5 / 30) train acc: 0.794000; val_acc: 0.744034\n",
      "(Epoch 6 / 30) train acc: 0.840000; val_acc: 0.779763\n",
      "(Epoch 7 / 30) train acc: 0.866000; val_acc: 0.797729\n",
      "(Epoch 8 / 30) train acc: 0.883000; val_acc: 0.793203\n",
      "(Epoch 9 / 30) train acc: 0.897000; val_acc: 0.820847\n",
      "(Epoch 10 / 30) train acc: 0.919000; val_acc: 0.823220\n",
      "(Iteration 101 / 300) loss: 0.395248\n",
      "(Epoch 11 / 30) train acc: 0.920000; val_acc: 0.826119\n",
      "(Epoch 12 / 30) train acc: 0.935000; val_acc: 0.831322\n",
      "(Epoch 13 / 30) train acc: 0.948000; val_acc: 0.835932\n",
      "(Epoch 14 / 30) train acc: 0.959000; val_acc: 0.843136\n",
      "(Epoch 15 / 30) train acc: 0.960000; val_acc: 0.846949\n",
      "(Epoch 16 / 30) train acc: 0.964000; val_acc: 0.842966\n",
      "(Epoch 17 / 30) train acc: 0.973000; val_acc: 0.845186\n",
      "(Epoch 18 / 30) train acc: 0.973000; val_acc: 0.849661\n",
      "(Epoch 19 / 30) train acc: 0.982000; val_acc: 0.847695\n",
      "(Epoch 20 / 30) train acc: 0.983000; val_acc: 0.849186\n",
      "(Iteration 201 / 300) loss: 0.068887\n",
      "(Epoch 21 / 30) train acc: 0.981000; val_acc: 0.848915\n",
      "(Epoch 22 / 30) train acc: 0.989000; val_acc: 0.850492\n",
      "(Epoch 23 / 30) train acc: 0.991000; val_acc: 0.850695\n",
      "(Epoch 24 / 30) train acc: 0.994000; val_acc: 0.850712\n",
      "(Epoch 25 / 30) train acc: 0.994000; val_acc: 0.848644\n",
      "(Epoch 26 / 30) train acc: 0.995000; val_acc: 0.850000\n",
      "(Epoch 27 / 30) train acc: 0.998000; val_acc: 0.851644\n",
      "(Epoch 28 / 30) train acc: 0.995000; val_acc: 0.850932\n",
      "(Epoch 29 / 30) train acc: 0.997000; val_acc: 0.854949\n",
      "(Epoch 30 / 30) train acc: 0.997000; val_acc: 0.852831\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=1000)\n",
    "data = dict(X_train=X_train, X_val=X_test, y_train=y_train, y_val=y_test)\n",
    "\n",
    "init_scale = 2 / np.sqrt(28*28) \n",
    "model = AffineReluAffineNet(hidden_dims=[30, 30, 30], \n",
    "                          input_dim=28*28, \n",
    "                          num_classes=10, \n",
    "                          reg=0, \n",
    "                          weight_scale=init_scale)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                lr_decay=0.95,\n",
    "                num_epochs=30, batch_size=100,\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'W1'), (0, 'W2'), (0, 'b1'), (0, 'b2'), (1, 'W1'), (1, 'W2'), (1, 'b1'), (1, 'b2'), (2, 'W1'), (2, 'W2'), (2, 'b1'), (2, 'b2'), (3, 'W'), (3, 'b')]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(model.params.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  2.30194354405\n",
      "(0, 'W1') relative error: 6.31e-06\n",
      "(0, 'W2') relative error: 1.74e-06\n",
      "(0, 'b1') relative error: 9.31e-08\n",
      "(0, 'b2') relative error: 1.08e-07\n",
      "(1, 'W1') relative error: 4.79e-05\n",
      "(1, 'W2') relative error: 6.55e-06\n",
      "(1, 'b1') relative error: 2.07e-08\n",
      "(1, 'b2') relative error: 7.67e-09\n",
      "(2, 'W') relative error: 1.51e-06\n",
      "(2, 'b') relative error: 1.21e-10\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  12.1133693468\n",
      "(0, 'W1') relative error: 1.17e-07\n",
      "(0, 'W2') relative error: 3.22e-08\n",
      "(0, 'b1') relative error: 2.69e-07\n",
      "(0, 'b2') relative error: 1.42e-07\n",
      "(1, 'W1') relative error: 1.61e-08\n",
      "(1, 'W2') relative error: 1.12e-07\n",
      "(1, 'b1') relative error: 2.20e-08\n",
      "(1, 'b2') relative error: 8.56e-08\n",
      "(2, 'W') relative error: 1.77e-08\n",
      "(2, 'b') relative error: 3.87e-10\n"
     ]
    }
   ],
   "source": [
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "    print ('Running check with reg = ', reg)\n",
    "    model = AffineReluAffineNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "    loss, grads = model.loss(X, y)\n",
    "    print ('Initial loss: ', loss)\n",
    "\n",
    "    for name in sorted(grads):\n",
    "        f = lambda _: model.loss(X, y)[0]\n",
    "        grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "        print ('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 16200) loss: 2.289934\n",
      "(Epoch 0 / 30) train acc: 0.118000; val_acc: 0.112833\n",
      "(Iteration 101 / 16200) loss: 0.498059\n",
      "(Iteration 201 / 16200) loss: 0.355993\n",
      "(Iteration 301 / 16200) loss: 0.254787\n",
      "(Iteration 401 / 16200) loss: 0.281160\n",
      "(Iteration 501 / 16200) loss: 0.175544\n",
      "(Epoch 1 / 30) train acc: 0.931000; val_acc: 0.931167\n",
      "(Iteration 601 / 16200) loss: 0.208472\n",
      "(Iteration 701 / 16200) loss: 0.136653\n",
      "(Iteration 801 / 16200) loss: 0.222881\n",
      "(Iteration 901 / 16200) loss: 0.086840\n",
      "(Iteration 1001 / 16200) loss: 0.254276\n",
      "(Epoch 2 / 30) train acc: 0.952000; val_acc: 0.945500\n",
      "(Iteration 1101 / 16200) loss: 0.081361\n",
      "(Iteration 1201 / 16200) loss: 0.306804\n",
      "(Iteration 1301 / 16200) loss: 0.160536\n",
      "(Iteration 1401 / 16200) loss: 0.136419\n",
      "(Iteration 1501 / 16200) loss: 0.163765\n",
      "(Iteration 1601 / 16200) loss: 0.164559\n",
      "(Epoch 3 / 30) train acc: 0.959000; val_acc: 0.954167\n",
      "(Iteration 1701 / 16200) loss: 0.175701\n",
      "(Iteration 1801 / 16200) loss: 0.199718\n",
      "(Iteration 1901 / 16200) loss: 0.107919\n",
      "(Iteration 2001 / 16200) loss: 0.184068\n",
      "(Iteration 2101 / 16200) loss: 0.148500\n",
      "(Epoch 4 / 30) train acc: 0.969000; val_acc: 0.962333\n",
      "(Iteration 2201 / 16200) loss: 0.094302\n",
      "(Iteration 2301 / 16200) loss: 0.114724\n",
      "(Iteration 2401 / 16200) loss: 0.135129\n",
      "(Iteration 2501 / 16200) loss: 0.101608\n",
      "(Iteration 2601 / 16200) loss: 0.083593\n",
      "(Epoch 5 / 30) train acc: 0.959000; val_acc: 0.962000\n",
      "(Iteration 2701 / 16200) loss: 0.106456\n",
      "(Iteration 2801 / 16200) loss: 0.109910\n",
      "(Iteration 2901 / 16200) loss: 0.089396\n",
      "(Iteration 3001 / 16200) loss: 0.038567\n",
      "(Iteration 3101 / 16200) loss: 0.206319\n",
      "(Iteration 3201 / 16200) loss: 0.045611\n",
      "(Epoch 6 / 30) train acc: 0.975000; val_acc: 0.957667\n",
      "(Iteration 3301 / 16200) loss: 0.114230\n",
      "(Iteration 3401 / 16200) loss: 0.090862\n",
      "(Iteration 3501 / 16200) loss: 0.088415\n",
      "(Iteration 3601 / 16200) loss: 0.050177\n",
      "(Iteration 3701 / 16200) loss: 0.053775\n",
      "(Epoch 7 / 30) train acc: 0.974000; val_acc: 0.955833\n",
      "(Iteration 3801 / 16200) loss: 0.078614\n",
      "(Iteration 3901 / 16200) loss: 0.233615\n",
      "(Iteration 4001 / 16200) loss: 0.059901\n",
      "(Iteration 4101 / 16200) loss: 0.030665\n",
      "(Iteration 4201 / 16200) loss: 0.124938\n",
      "(Iteration 4301 / 16200) loss: 0.033121\n",
      "(Epoch 8 / 30) train acc: 0.980000; val_acc: 0.963500\n",
      "(Iteration 4401 / 16200) loss: 0.089034\n",
      "(Iteration 4501 / 16200) loss: 0.061771\n",
      "(Iteration 4601 / 16200) loss: 0.117049\n",
      "(Iteration 4701 / 16200) loss: 0.061773\n",
      "(Iteration 4801 / 16200) loss: 0.061381\n",
      "(Epoch 9 / 30) train acc: 0.973000; val_acc: 0.959500\n",
      "(Iteration 4901 / 16200) loss: 0.057288\n",
      "(Iteration 5001 / 16200) loss: 0.072382\n",
      "(Iteration 5101 / 16200) loss: 0.033722\n",
      "(Iteration 5201 / 16200) loss: 0.059934\n",
      "(Iteration 5301 / 16200) loss: 0.111482\n",
      "(Epoch 10 / 30) train acc: 0.973000; val_acc: 0.958667\n",
      "(Iteration 5401 / 16200) loss: 0.018403\n",
      "(Iteration 5501 / 16200) loss: 0.090765\n",
      "(Iteration 5601 / 16200) loss: 0.085855\n",
      "(Iteration 5701 / 16200) loss: 0.034460\n",
      "(Iteration 5801 / 16200) loss: 0.051774\n",
      "(Iteration 5901 / 16200) loss: 0.012666\n",
      "(Epoch 11 / 30) train acc: 0.989000; val_acc: 0.968500\n",
      "(Iteration 6001 / 16200) loss: 0.055220\n",
      "(Iteration 6101 / 16200) loss: 0.013023\n",
      "(Iteration 6201 / 16200) loss: 0.005064\n",
      "(Iteration 6301 / 16200) loss: 0.029431\n",
      "(Iteration 6401 / 16200) loss: 0.049590\n",
      "(Epoch 12 / 30) train acc: 0.984000; val_acc: 0.968167\n",
      "(Iteration 6501 / 16200) loss: 0.067374\n",
      "(Iteration 6601 / 16200) loss: 0.009733\n",
      "(Iteration 6701 / 16200) loss: 0.117837\n",
      "(Iteration 6801 / 16200) loss: 0.107327\n",
      "(Iteration 6901 / 16200) loss: 0.047718\n",
      "(Iteration 7001 / 16200) loss: 0.054443\n",
      "(Epoch 13 / 30) train acc: 0.987000; val_acc: 0.963833\n",
      "(Iteration 7101 / 16200) loss: 0.056292\n",
      "(Iteration 7201 / 16200) loss: 0.004012\n",
      "(Iteration 7301 / 16200) loss: 0.024809\n",
      "(Iteration 7401 / 16200) loss: 0.051720\n",
      "(Iteration 7501 / 16200) loss: 0.014572\n",
      "(Epoch 14 / 30) train acc: 0.990000; val_acc: 0.968167\n",
      "(Iteration 7601 / 16200) loss: 0.036190\n",
      "(Iteration 7701 / 16200) loss: 0.001646\n",
      "(Iteration 7801 / 16200) loss: 0.009762\n",
      "(Iteration 7901 / 16200) loss: 0.022916\n",
      "(Iteration 8001 / 16200) loss: 0.004112\n",
      "(Epoch 15 / 30) train acc: 0.985000; val_acc: 0.967833\n",
      "(Iteration 8101 / 16200) loss: 0.022423\n",
      "(Iteration 8201 / 16200) loss: 0.037498\n",
      "(Iteration 8301 / 16200) loss: 0.028538\n",
      "(Iteration 8401 / 16200) loss: 0.056206\n",
      "(Iteration 8501 / 16200) loss: 0.074757\n",
      "(Iteration 8601 / 16200) loss: 0.078978\n",
      "(Epoch 16 / 30) train acc: 0.989000; val_acc: 0.969167\n",
      "(Iteration 8701 / 16200) loss: 0.011365\n",
      "(Iteration 8801 / 16200) loss: 0.016664\n",
      "(Iteration 8901 / 16200) loss: 0.101804\n",
      "(Iteration 9001 / 16200) loss: 0.005447\n",
      "(Iteration 9101 / 16200) loss: 0.018516\n",
      "(Epoch 17 / 30) train acc: 0.992000; val_acc: 0.968833\n",
      "(Iteration 9201 / 16200) loss: 0.038017\n",
      "(Iteration 9301 / 16200) loss: 0.041796\n",
      "(Iteration 9401 / 16200) loss: 0.023535\n",
      "(Iteration 9501 / 16200) loss: 0.035973\n",
      "(Iteration 9601 / 16200) loss: 0.044234\n",
      "(Iteration 9701 / 16200) loss: 0.033446\n",
      "(Epoch 18 / 30) train acc: 0.993000; val_acc: 0.969833\n",
      "(Iteration 9801 / 16200) loss: 0.044387\n",
      "(Iteration 9901 / 16200) loss: 0.130114\n",
      "(Iteration 10001 / 16200) loss: 0.170798\n",
      "(Iteration 10101 / 16200) loss: 0.017864\n",
      "(Iteration 10201 / 16200) loss: 0.006515\n",
      "(Epoch 19 / 30) train acc: 0.992000; val_acc: 0.968167\n",
      "(Iteration 10301 / 16200) loss: 0.017601\n",
      "(Iteration 10401 / 16200) loss: 0.010299\n",
      "(Iteration 10501 / 16200) loss: 0.065253\n",
      "(Iteration 10601 / 16200) loss: 0.024475\n",
      "(Iteration 10701 / 16200) loss: 0.030334\n",
      "(Epoch 20 / 30) train acc: 0.993000; val_acc: 0.968500\n",
      "(Iteration 10801 / 16200) loss: 0.022097\n",
      "(Iteration 10901 / 16200) loss: 0.005919\n",
      "(Iteration 11001 / 16200) loss: 0.027546\n",
      "(Iteration 11101 / 16200) loss: 0.068402\n",
      "(Iteration 11201 / 16200) loss: 0.052039\n",
      "(Iteration 11301 / 16200) loss: 0.026964\n",
      "(Epoch 21 / 30) train acc: 0.993000; val_acc: 0.970333\n",
      "(Iteration 11401 / 16200) loss: 0.010748\n",
      "(Iteration 11501 / 16200) loss: 0.043585\n",
      "(Iteration 11601 / 16200) loss: 0.006943\n",
      "(Iteration 11701 / 16200) loss: 0.010369\n",
      "(Iteration 11801 / 16200) loss: 0.021803\n",
      "(Epoch 22 / 30) train acc: 0.992000; val_acc: 0.963833\n",
      "(Iteration 11901 / 16200) loss: 0.010776\n",
      "(Iteration 12001 / 16200) loss: 0.077872\n",
      "(Iteration 12101 / 16200) loss: 0.020978\n",
      "(Iteration 12201 / 16200) loss: 0.016578\n",
      "(Iteration 12301 / 16200) loss: 0.045015\n",
      "(Iteration 12401 / 16200) loss: 0.007802\n",
      "(Epoch 23 / 30) train acc: 0.993000; val_acc: 0.968667\n",
      "(Iteration 12501 / 16200) loss: 0.014112\n",
      "(Iteration 12601 / 16200) loss: 0.065113\n",
      "(Iteration 12701 / 16200) loss: 0.002806\n",
      "(Iteration 12801 / 16200) loss: 0.045317\n",
      "(Iteration 12901 / 16200) loss: 0.027531\n",
      "(Epoch 24 / 30) train acc: 0.989000; val_acc: 0.967167\n",
      "(Iteration 13001 / 16200) loss: 0.007213\n",
      "(Iteration 13101 / 16200) loss: 0.005662\n",
      "(Iteration 13201 / 16200) loss: 0.007752\n",
      "(Iteration 13301 / 16200) loss: 0.046443\n",
      "(Iteration 13401 / 16200) loss: 0.047933\n",
      "(Epoch 25 / 30) train acc: 0.990000; val_acc: 0.965000\n",
      "(Iteration 13501 / 16200) loss: 0.006396\n",
      "(Iteration 13601 / 16200) loss: 0.096107\n",
      "(Iteration 13701 / 16200) loss: 0.026247\n",
      "(Iteration 13801 / 16200) loss: 0.016074\n",
      "(Iteration 13901 / 16200) loss: 0.025935\n",
      "(Iteration 14001 / 16200) loss: 0.012918\n",
      "(Epoch 26 / 30) train acc: 0.989000; val_acc: 0.967833\n",
      "(Iteration 14101 / 16200) loss: 0.010701\n",
      "(Iteration 14201 / 16200) loss: 0.039850\n",
      "(Iteration 14301 / 16200) loss: 0.006207\n",
      "(Iteration 14401 / 16200) loss: 0.013887\n",
      "(Iteration 14501 / 16200) loss: 0.002156\n",
      "(Epoch 27 / 30) train acc: 0.993000; val_acc: 0.969500\n",
      "(Iteration 14601 / 16200) loss: 0.009997\n",
      "(Iteration 14701 / 16200) loss: 0.002152\n",
      "(Iteration 14801 / 16200) loss: 0.001221\n",
      "(Iteration 14901 / 16200) loss: 0.002964\n",
      "(Iteration 15001 / 16200) loss: 0.105469\n",
      "(Iteration 15101 / 16200) loss: 0.002449\n",
      "(Epoch 28 / 30) train acc: 0.998000; val_acc: 0.969833\n",
      "(Iteration 15201 / 16200) loss: 0.002675\n",
      "(Iteration 15301 / 16200) loss: 0.000300\n",
      "(Iteration 15401 / 16200) loss: 0.057870\n",
      "(Iteration 15501 / 16200) loss: 0.005588\n",
      "(Iteration 15601 / 16200) loss: 0.066467\n",
      "(Epoch 29 / 30) train acc: 0.991000; val_acc: 0.969333\n",
      "(Iteration 15701 / 16200) loss: 0.006061\n",
      "(Iteration 15801 / 16200) loss: 0.003609\n",
      "(Iteration 15901 / 16200) loss: 0.003295\n",
      "(Iteration 16001 / 16200) loss: 0.006802\n",
      "(Iteration 16101 / 16200) loss: 0.027013\n",
      "(Epoch 30 / 30) train acc: 0.996000; val_acc: 0.968333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.9)\n",
    "data = dict(X_train=X_train, X_val=X_test, y_train=y_train, y_val=y_test)\n",
    "\n",
    "# for it in range(30):\n",
    "init_scale = 2 / np.sqrt(28*28) \n",
    "model = AffineReluAffineNet(hidden_dims=[30, 25, 30], \n",
    "                          input_dim=28*28, \n",
    "                          num_classes=10, \n",
    "                          reg=0, \n",
    "                          weight_scale=init_scale)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                lr_decay=0.95,\n",
    "                num_epochs=30, batch_size=100,\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submodel = model[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<models.layers.AffineReluAffine at 0x11954ea90>,\n",
       " <models.layers.AffineReluAffine at 0x11954e198>,\n",
       " <models.layers.AffineReluAffine at 0x119552dd8>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
